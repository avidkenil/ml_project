{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from os import path, makedirs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path='../data/', is_clean=0, is_os=0):\n",
    "    clean = '_clean' if is_clean else ''\n",
    "    os = '_os' if is_os else ''\n",
    "    data_sets = {}\n",
    "    data_cols = [\n",
    "        'data', 'X_train', 'X_val', 'X_train_val', 'X_test', \\\n",
    "        'y_train', 'y_val', 'y_train_val', 'y_test'\n",
    "    ]\n",
    "    \n",
    "    for i, col in enumerate(data_cols):\n",
    "        data_cols[i] = col + clean + os\n",
    "    \n",
    "    for col in data_cols:\n",
    "        data_sets[col] = pickle.load(open(data_path+'{}.pkl'.format(col),'rb'))\n",
    "    \n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_clean, is_os = 1, 0\n",
    "clean, os = '_clean', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = load_data('../data/', is_clean=1, is_os=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d'aww match background colour -pron- seemingly...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man -pron- not try edit war -pron- guy con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>not real suggestion improvement wonder section...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations good use tool good · talk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article revert not ban</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word nonsense offensive -pron- not inten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edit username hardcore metallica f...      0   \n",
       "1  000103f0d9cfb60f  d'aww match background colour -pron- seemingly...      0   \n",
       "2  000113f07ec002fd  hey man -pron- not try edit war -pron- guy con...      0   \n",
       "3  0001b41b1c6bb37e  not real suggestion improvement wonder section...      0   \n",
       "4  0001d958c54c6e35                      sir hero chance remember page      0   \n",
       "5  00025465d4725e87          congratulations good use tool good · talk      0   \n",
       "6  0002bcb3da6cb337                               cocksucker piss work      1   \n",
       "7  00031b1e95af7921  vandalism matt shirvington article revert not ban      0   \n",
       "8  00037261f536c51d  sorry word nonsense offensive -pron- not inten...      0   \n",
       "9  00040093b2687caa               alignment subject contrary dulithgow      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['data'+clean+os].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101689</th>\n",
       "      <td>202d64bd4c2bd9a4</td>\n",
       "      <td>champion hurdle delighted use 1 2_3 image uplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26429</th>\n",
       "      <td>4601831cd03ec679</td>\n",
       "      <td>edit war currently appear engage edit war note...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62499</th>\n",
       "      <td>a73c6f5b69d963be</td>\n",
       "      <td>-pron- wrong bud ready use taran boi verdict n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>1ad558921b36c611</td>\n",
       "      <td>attempt change las vegas season las vegas augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16254</th>\n",
       "      <td>2adc0c27c1165eef</td>\n",
       "      <td>people arab homosexual bad thing d**n f***in h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "101689  202d64bd4c2bd9a4  champion hurdle delighted use 1 2_3 image uplo...\n",
       "26429   4601831cd03ec679  edit war currently appear engage edit war note...\n",
       "62499   a73c6f5b69d963be  -pron- wrong bud ready use taran boi verdict n...\n",
       "10145   1ad558921b36c611  attempt change las vegas season las vegas augu...\n",
       "16254   2adc0c27c1165eef  people arab homosexual bad thing d**n f***in h..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['X_train'+clean+os].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic:\n",
      "y_train_clean: 9.528%\ty_val_clean: 9.551%\ty_train_val_clean: 9.533%\ty_test_clean: 9.789%\t\n",
      "\n",
      "severe_toxic:\n",
      "y_train_clean: 1.005%\ty_val_clean: 0.993%\ty_train_val_clean: 1.002%\ty_test_clean: 0.990%\t\n",
      "\n",
      "obscene:\n",
      "y_train_clean: 5.321%\ty_val_clean: 5.274%\ty_train_val_clean: 5.309%\ty_test_clean: 5.239%\t\n",
      "\n",
      "threat:\n",
      "y_train_clean: 0.287%\ty_val_clean: 0.295%\ty_train_val_clean: 0.289%\ty_test_clean: 0.342%\t\n",
      "\n",
      "insult:\n",
      "y_train_clean: 4.960%\ty_val_clean: 4.860%\ty_train_val_clean: 4.935%\ty_test_clean: 4.941%\t\n",
      "\n",
      "identity_hate:\n",
      "y_train_clean: 0.902%\ty_val_clean: 0.833%\ty_train_val_clean: 0.885%\ty_test_clean: 0.862%\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print value counts for each target\n",
    "for col in target_cols:\n",
    "    print('{}:'.format(col))\n",
    "    for data in data_sets:\n",
    "        if 'y' in data:\n",
    "            value_counts = data_sets[data][col].value_counts()\n",
    "            print('{}: {:.3f}%\\t'.format(data, 100*value_counts[1]/sum(value_counts)), end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = 1000\n",
    "n_grams = 2\n",
    "ngram_range = list(map(lambda x: x+1,range(n_grams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngrams(data, num_feats, ngram_range, pickle_path='../pickle_objects/', is_clean=1, is_os=0):\n",
    "    clean = '_clean' if is_clean else ''\n",
    "    os = '_os' if is_os else ''\n",
    "    ngrams = {}\n",
    "    vec_params = {'analyzer': 'word', 'lowercase': True,'max_features': num_feats, 'ngram_range': ngram_range}\n",
    "    \n",
    "    for vec in ['countvec', 'tfidf']:\n",
    "        # Load vectorizer if present\n",
    "        file_name = '{}{}_{}_ngrams_{}{}.pkl'.format(pickle_path, vec, num_feats, n_grams, clean+os)\n",
    "        if path.isfile(file_name):\n",
    "            ngrams[vec] = pickle.load(open(file_name, 'rb'))\n",
    "        else:\n",
    "            # Fit, store, and load vectorizer\n",
    "            ngrams_vec = CountVectorizer(**vec_params) if vec == 'countvec' else TfidfVectorizer(**vec_params)\n",
    "            ngrams_vec.fit(data['comment_text'])\n",
    "            ngrams[vec] = ngrams_vec\n",
    "            if not path.exists(pickle_path):\n",
    "                makedirs(pickle_path)\n",
    "            pickle.dump(ngrams_vec, open(file_name, 'wb'))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range, \\\n",
    "                     '../pickle_objects/', is_clean, is_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ngrams(data_set, data_cols, ngrams):\n",
    "    for data in data_cols:\n",
    "        for vec in ['countvec', 'tfidf']:\n",
    "            data_sets[data+'_'+vec] = ngrams[vec].transform(data_sets[data]['comment_text'])\n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = transform_to_ngrams(data_sets, ['X_train'+clean+os, 'X_val'+clean+os, \\\n",
    "                                            'X_train_val'+clean+os, 'X_test'+clean+os], ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(base_model, X, y, params, target_cols, scoring='roc_auc', cv=None):\n",
    "    models = {}\n",
    "    for target in target_cols:\n",
    "        models[target] = {}\n",
    "        if cv:\n",
    "            model_target = GridSearchCV(base_model, params, cv=cv, scoring=scoring, n_jobs=-1, refit=False)\n",
    "            model_target.fit(X, y[target])\n",
    "            models[target]['params'], models[target]['params'], models[target]['score'] = \\\n",
    "            model_target, model_target.best_params_, np.round(model_target.best_score_, 4)\n",
    "        else:\n",
    "            base_model(**params).fit(X, y)\n",
    "            models[target] = model_target\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_all_models(data_sets, data_cols, model_list, param_grids, target_cols, cv=None):\n",
    "    best_models, best_params, best_scores = {}, {}, {}\n",
    "    for (X, y) in data_cols:\n",
    "        best_models[X], best_params[X], best_scores[X] = {}, {}, {}\n",
    "        for model in model_list:\n",
    "            best_models[X][model] = fit_model(model_list[model], data_sets[X], \\\n",
    "                                              data_sets[y], param_grids[model], \\\n",
    "                                              target_cols, scoring='roc_auc', cv=cv)\n",
    "            print('Model = {}'.format(model))\n",
    "            print(json.dumps(best_models[X][model], indent=4))\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_and_probas(model, X):\n",
    "    probabilities = model.predict_proba(X)\n",
    "    probabilities = np.squeeze(np.asarray(probabilities.todense()))\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\n",
    "    'bnb': BernoulliNB(),\n",
    "    'gnb': GaussianNB(),\n",
    "    'lrl1': LogisticRegression(penalty='l1'),\n",
    "    'lrl2': LogisticRegression(penalty='l2'),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'svm': SVC(kernel='linear')\n",
    "}\n",
    "    \n",
    "param_grids = {\n",
    "    'bnb': {},\n",
    "    'gnb': {},\n",
    "    'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1, 13, 3)), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "    'lrl2': {'C': np.concatenate((np.reciprocal(np.arange(1, 13, 3)), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "    'rf': {\n",
    "        'n_estimators': np.arange(50, 250, 50),\n",
    "        'max_features': ['auto', 'log2'],\n",
    "        'max_depth': np.arange(3, 13, 2)\n",
    "    },\n",
    "    'xgb': {'n_estimators': [1]},\n",
    "    'svm': {'C': np.concatenate((np.arange(1, 13, 3), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predefined split for CV\n",
    "# 0 corresponds to val, -1 to train\n",
    "val_fold = [-1]*len(data_sets['X_train'+clean+os]) + [0]*len(data_sets['X_val'+clean+os])\n",
    "predefined_split = PredefinedSplit(test_fold=val_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model = lrl1\n",
      "{\n",
      "    \"toxic\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.1\n",
      "        },\n",
      "        \"score\": 0.8888\n",
      "    },\n",
      "    \"severe_toxic\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.1\n",
      "        },\n",
      "        \"score\": 0.9168\n",
      "    },\n",
      "    \"obscene\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.01\n",
      "        },\n",
      "        \"score\": 0.9192\n",
      "    },\n",
      "    \"threat\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.1\n",
      "        },\n",
      "        \"score\": 0.8457\n",
      "    },\n",
      "    \"insult\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.1\n",
      "        },\n",
      "        \"score\": 0.8948\n",
      "    },\n",
      "    \"identity_hate\": {\n",
      "        \"params\": {\n",
      "            \"C\": 0.1\n",
      "        },\n",
      "        \"score\": 0.8689\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Test runs\n",
    "model_list = {\n",
    "    'lrl1': LogisticRegression(penalty='l1')\n",
    "}\n",
    "    \n",
    "param_grids = {\n",
    "    'lrl1': {'C': [1e-1, 1e-2]}\n",
    "}\n",
    "\n",
    "best_models = fit_all_models(data_sets, [('X_train_val'+clean+os+'_countvec', 'y_train_val'+clean+os)], \\\n",
    "                             model_list, param_grids, target_cols, cv=predefined_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit individual BernoulliNB models for each target with Count Vectorizer\n",
    "bnb_countvec = BinaryRelevance(BernoulliNB())\n",
    "bnb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "predictions_bnb_countvec = bnb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit individual GaussianNB models for each target with Count Vectorizer\n",
    "gnb_countvec = BinaryRelevance(GaussianNB())\n",
    "gnb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "predictions_gnb_countvec = gnb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit individual GaussianNB models for each target with TF-IDF Vectorizer\n",
    "gnb_tfidf = BinaryRelevance(GaussianNB())\n",
    "gnb_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_gnb_tfidf = gnb_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit individual Logistic Regression+l1 models for each target with TF-IDF Vectorizer\n",
    "lr1_tfidf = BinaryRelevance(LogisticRegression(penalty='l1'))\n",
    "lr1_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_lr1_tfidf = lr1_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit individual Logistic Regression+l2 models for each target with TF-IDF Vectorizer\n",
    "lr2_tfidf = BinaryRelevance(LogisticRegression(penalty='l2'))\n",
    "lr2_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_lr2_tfidf = lr2_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit RandomForestClassifier for each target with Count Vectorizer\n",
    "rf_countvec = RandomForestClassifier(n_estimators=100)\n",
    "rf_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "probabilities_rf_countvec = rf_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit RandomForestClassifier for each target with TF-IDF Vectorizer\n",
    "rf_tfidf = RandomForestClassifier(n_estimators=100)\n",
    "rf_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "probabilities_rf_tfidf = rf_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# # Fit XGBClassifier for each target with Count Vectorizer\n",
    "# xgb_countvec = BinaryRelevance(XGBClassifier(n_estimators=1))\n",
    "# xgb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "# predictions_xgb_countvec = xgb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# # Fit XGBClassifier for each target with TF-IDF Vectorizer\n",
    "# xgb_tfidf = BinaryRelevance(XGBClassifier(n_estimators=1))\n",
    "# xgb_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "# predictions_xgb_tfidf = xgb_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "\n",
    "# # Fit individual GaussianNB models for each target with TF-IDF Vectorizer\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train_val_tfidf)\n",
    "# X_train_val_tfidf = scaler.transform(X_train_val_tfidf)\n",
    "# X_test_tfidf = scaler.transform(X_test_tfidf)\n",
    "# svc_tfidf = BinaryRelevance(SVC(kernel='linear'))\n",
    "# svc_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "# predictions_svc_tfidf = svc_tfidf.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities of each class for Count Vectorizer (BernoulliNB)\n",
    "probabilities_bnb_countvec = np.squeeze(np.asarray(predictions_bnb_countvec.todense()))\n",
    "\n",
    "# Predict probabilities of each class for Count Vectorizer and TF-IDF Vectorizer (GaussianNB)\n",
    "probabilities_gnb_countvec = np.squeeze(np.asarray(predictions_gnb_countvec.todense()))\n",
    "probabilities_gnb_tfidf = np.squeeze(np.asarray(predictions_gnb_tfidf.todense()))\n",
    "\n",
    "\n",
    "# Predict probabilities of each class for TF-IDF Vectorizer (LogisticRegression+l1)\n",
    "probabilities_lr1_tfidf = np.squeeze(np.asarray(predictions_lr1_tfidf.todense()))\n",
    "\n",
    "# Predict probabilities of each class for TF-IDF Vectorizer (LogisticRegression+l2)\n",
    "probabilities_lr2_tfidf = np.squeeze(np.asarray(predictions_lr2_tfidf.todense()))\n",
    "\n",
    "# # Predict probabilities of each class for TF-IDF Vectorizer (SVC(linear kernel))\n",
    "# probabilities_svc_tfidf = np.squeeze(np.asarray(predictions_svc_tfidf.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC-AUC values of each class for Count Vectorizer (BernoulliNB)\n",
    "auc_bnb_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_bnb_countvec[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_bnb_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for BernoulliNB with Count Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for Count Vectorizer (GaussianNB)\n",
    "auc_gnb_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_gnb_countvec[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_gnb_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for GaussianNB with Count Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (GaussianNB)\n",
    "auc_gnb_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_gnb_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_gnb_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for GaussianNB with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (LogisticRegression+l1)\n",
    "auc_lr1_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_lr1_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_lr1_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for LogisticRegression+l1 with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (LogisticRegression+l2)\n",
    "auc_lr2_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_lr2_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_lr2_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for LogisticRegression+l2 with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for Count Vectorizer (RandomForestClassifier)\n",
    "auc_rf_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_rf_countvec[i][:,1])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_rf_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for Random Forest with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (RandomForestClassifier)\n",
    "auc_rf_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_rf_tfidf[i][:,1])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_rf_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for Random Forest with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for Count Vectorizer (XGBClassifier)\n",
    "# auc_xgb_countvec = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_xgb_countvec[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_xgb_countvec.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for XGBoost with Count Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for TfIdf Vectorizer (XGBClassifier)\n",
    "# auc_xgb_tfidf = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_xgb_tfidf[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_xgb_tfidf.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for XGBoost with TfIdf Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for TfIdf Vectorizer (SVC(linear kernel))\n",
    "# auc_svc_tfidf = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_svc_tfidf[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_svc_tfidf.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for LogisticRegression with TfIdf Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean column-wise ROC-AUC values\n",
    "print('ROC-AUC for BernoulliNB with Count Vectorizer = {:.4f}'.format(np.mean(auc_bnb_countvec)))\n",
    "print('ROC-AUC for GaussianNB with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_gnb_tfidf)))\n",
    "print('ROC-AUC for GaussianNB with Count Vectorizer = {:.4f}'.format(np.mean(auc_gnb_countvec)))\n",
    "print('ROC-AUC for RandomForest with Count Vectorizer = {:.4f}'.format(np.mean(auc_rf_countvec)))\n",
    "print('ROC-AUC for RandomForest with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_rf_tfidf)))\n",
    "print('ROC-AUC for LogisticRegression+l1 with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_lr1_tfidf)))\n",
    "print('ROC-AUC for LogisticRegression+l2 with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_lr2_tfidf)))\n",
    "# print('ROC-AUC for XGBoost with Count Vectorizer = {:.4f}'.format(np.mean(auc_xgb_countvec)))\n",
    "# print('ROC-AUC for XGBoost with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_xgb_tfidf)))\n",
    "# print('ROC-AUC for SVC with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_svc_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = pd.DataFrame()\n",
    "aucs['bnb_countvec'] = auc_bnb_countvec\n",
    "aucs['gnb_tfidfvec'] = auc_gnb_tfidf\n",
    "aucs['gnb_countvec'] = auc_gnb_countvec\n",
    "aucs['rf_countvec'] = auc_rf_countvec\n",
    "aucs['rf_tfidfvec'] = auc_rf_tfidf\n",
    "aucs['lr1_tfidfvec'] = auc_lr1_tfidf\n",
    "aucs['lr2_tfidfvec'] = auc_lr2_tfidf\n",
    "# aucs['xgb_countvec'] = auc_xgb_countvec\n",
    "# aucs['xgb_tfidfvec'] = auc_xgb_tfidf\n",
    "# aucs['svc_tfidfvec'] = auc_svc_tfidf\n",
    "\n",
    "aucs = aucs.T\n",
    "aucs.columns = target_cols\n",
    "aucs['mean'] = np.mean(aucs[target_cols], axis=1)\n",
    "aucs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
