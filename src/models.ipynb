{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from os import path, makedirs\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import clone\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from nbsvm import NBSVMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print JSON objects\n",
    "def pretty_print(data_dict):\n",
    "    try:\n",
    "        print(json.dumps(data_dict, indent=4))\n",
    "    except TypeError:\n",
    "        print(data_dict)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# Create all required folder paths (recursively)\n",
    "def create_paths(path_list):\n",
    "    print('Creating all folder paths... ', end='', flush=True)\n",
    "    for folder_path in path_list:\n",
    "        if not path.exists(folder_path):\n",
    "            makedirs(folder_path)\n",
    "    print('Done.')\n",
    "\n",
    "# Dump data to disk if not present\n",
    "def dump_data(data, name, file_path, force=False):\n",
    "    if force or not path.isfile(file_path):\n",
    "        print('Dumping {}... '.format(name), end='', flush=True)\n",
    "        pickle.dump(data, open(file_path, 'wb'))\n",
    "        print('Done.')\n",
    "    else:\n",
    "        print('Did not dump {}: File already exists in \"{}\".'.format(name, file_path))\n",
    "\n",
    "# Load all data sets\n",
    "def load_data(data_cols, data_path='../data/', clean='_clean', os=''):\n",
    "    print('Loading data... ', end='', flush=True)\n",
    "    data_sets = {}\n",
    "    \n",
    "    for col in data_cols:\n",
    "        data_sets[col] = pickle.load(open(data_path+'{}.pkl'.format(col),'rb'))\n",
    "\n",
    "    print('Done.')\n",
    "    return data_sets\n",
    "\n",
    "# Load all ngrams data if present, otherwise fit on data and dump them\n",
    "def load_ngrams(data_sets, data_col, num_feats, ngrams, vectorizers, pickle_path='../pickle_objects/', clean='_clean', os=''):\n",
    "    data_col += clean+os\n",
    "    ngrams_data = {}\n",
    "    ngram_range = list(map(lambda x: x+1,range(ngrams)))\n",
    "    vec_params = {'analyzer': 'word', 'lowercase': True,'max_features': num_feats, 'ngram_range': ngram_range}\n",
    "    \n",
    "    for vec in vectorizers:\n",
    "        # Load vectorizer if present\n",
    "        file_name = '{}{}_ngrams_{}_{}_{}.pkl'.format(pickle_path, vec, data_col, num_feats, ngrams)\n",
    "        if path.isfile(file_name):\n",
    "            print('Loading {} ngrams... '.format(vec), end='', flush=True)\n",
    "            ngrams_data[vec] = pickle.load(open(file_name, 'rb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            # Fit, store, and load vectorizer\n",
    "            print('{} ngrams not found. Fitting them... '.format(vec), end='', flush=True)\n",
    "            ngrams_vec = CountVectorizer(**vec_params) if vec == 'countvec' else TfidfVectorizer(**vec_params)\n",
    "            ngrams_vec.fit(data_sets[data_col]['comment_text'])\n",
    "            ngrams_data[vec] = ngrams_vec\n",
    "            dump_data(ngrams_vec, '{} ngrams'.format(vec), file_name)\n",
    "    return ngrams_data\n",
    "\n",
    "# Transform data on fitted ngrams data\n",
    "def transform_to_ngrams(data_sets, data_cols, ngrams_data, vectorizers):\n",
    "    print('Transforming data to ngrams... ', end='', flush=True)\n",
    "    for data in data_cols:\n",
    "        for vec in vectorizers:\n",
    "            data_sets[data+'_'+vec] = ngrams_data[vec].transform(data_sets[data]['comment_text'])\n",
    "    print('Done.')\n",
    "    return data_sets\n",
    "\n",
    "# Extract features and to data\n",
    "def generate_features(data_sets, data_cols, vectorizers):\n",
    "    print('Extracting features from data...')\n",
    "\n",
    "    # Get all data sets with features\n",
    "    X_cols = [col for col in data_cols if 'X' in col]\n",
    "    \n",
    "    # Add features\n",
    "    for col in X_cols:\n",
    "        for vec in vectorizers:\n",
    "            # Comment Text Length\n",
    "            print(\"\\tGenerating 'comment_length' for {}_{}... \".format(col, vec), end='', flush=True)\n",
    "            data_sets[col+'_'+vec+features] = np.hstack((data_sets[col+'_'+vec].todense(), \\\n",
    "                                                data_sets[col]['comment_text'].str.len().values.reshape(-1,1)))\n",
    "            print('Done.')\n",
    "\n",
    "            # Standard Deviation of Word Length in Comment Text\n",
    "            print(\"\\tGenerating 'word_length_std' for {}_{}... \".format(col, vec), end='', flush=True)\n",
    "            stddevs = np.array([])\n",
    "            for row in data_sets[col]['comment_text'].str.split().iteritems():\n",
    "                value = np.std([len(word) for word in row[1]]) if len(row[1]) else 0.\n",
    "                stddevs = np.append(stddevs, value)\n",
    "            print('Done.')\n",
    "            data_sets[col+'_'+vec+features] = np.hstack((data_sets[col+'_'+vec+features], stddevs.reshape(-1,1)))\n",
    "            \n",
    "            print('Converting back to sparse matrix... ', end='', flush=True)\n",
    "            data_sets[col+'_'+vec+features] = sparse.csr_matrix(data_sets[col+'_'+vec+features])\n",
    "            print('Done.')\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return data_sets\n",
    "\n",
    "# Dump all models of a type fitted on all target columns\n",
    "def dump_models(model, X, model_name, target_cols, model_path='../pickle_objects/models/', force=False):\n",
    "    for target in target_cols:\n",
    "        file_name = '{}{}_{}_{}.pkl'.format(model_path, model_name, X, target)\n",
    "        if force or not path.isfile(file_name):\n",
    "            print('\\t\\tDumping {} fitted on {}... '.format(model_name, target), end='', flush=True)\n",
    "            pickle.dump(model[target], open(file_name, 'wb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('\\t\\tDid not dump {} fitted on {}: File already exists in \"{}\".' \\\n",
    "                  .format(model_name, target, file_name))\n",
    "\n",
    "# Fit a model on all target columns after performing grid search or with best parameters\n",
    "def fit_model(base_model, X, y, param_grid, target_cols, scoring='roc_auc', cv=None):\n",
    "    if cv:\n",
    "        models, mean_val_scores, params = {}, [], []\n",
    "        for target in target_cols:\n",
    "            print('\\t\\tRunning for {}... '.format(target), end='', flush=True)\n",
    "            model_target = GridSearchCV(base_model, param_grid, cv=cv, scoring=scoring, n_jobs=4, refit=False)\n",
    "            model_target.fit(X, y[target])\n",
    "            print('Done.')\n",
    "            mean_val_scores.append(model_target.cv_results_['mean_test_score'])\n",
    "            if not params:\n",
    "                params = model_target.cv_results_['params']\n",
    "        mean_val_scores = np.mean(np.array(mean_val_scores), axis=0)\n",
    "        best_param_idx = np.argmax(mean_val_scores)\n",
    "        models['best_params_'], models['best_mean_score_'] = \\\n",
    "        params[best_param_idx], mean_val_scores[best_param_idx]\n",
    "    else:\n",
    "        models = {}\n",
    "        for target in target_cols:\n",
    "            model = clone(base_model)\n",
    "            print('\\t\\tRunning for {}... '.format(target), end='', flush=True)\n",
    "            model.set_params(**param_grid).fit(X, y[target])\n",
    "            models[target] = model\n",
    "            print('Done.')\n",
    "    return models\n",
    "\n",
    "# Fit all models on all target columns or dump the refitted ones with best parameters\n",
    "def fit_all_models(data_sets, data_cols, model_list, param_grids, target_cols, \\\n",
    "                   model_path='../pickle_path/models/', cv=None):\n",
    "    best_models, best_params, best_scores = {}, {}, {}\n",
    "    X, y = data_cols\n",
    "    for model in model_list:\n",
    "        print('\\tRunning {}...'.format(model))\n",
    "        best_models[model] = fit_model(model_list[model], data_sets[X], data_sets[y], \\\n",
    "                                       param_grids[model], target_cols, 'roc_auc', cv)\n",
    "        print('\\tDone.')\n",
    "        if cv:\n",
    "            pretty_print(best_models[model])\n",
    "        else:\n",
    "            print('\\tDumping {}... '.format(model))\n",
    "            dump_models(best_models[model], X, model, target_cols, model_path)\n",
    "            print('\\tDone.')\n",
    "    return best_models\n",
    "\n",
    "# Refit all models on all target columns with best parameters\n",
    "def refit_best_models(data_sets, model_list, data_cols, best_models, \\\n",
    "                      target_cols, model_path='../pickle_path/models/'):\n",
    "    # Refit all models with all data sets with best hyperparameters\n",
    "    print('Refitting with best parameters...')\n",
    "    best_params = {}\n",
    "    for model in model_list:\n",
    "        best_params[model] = best_models[model]['best_params_']\n",
    "    best_refitted_models = fit_all_models(data_sets, data_cols, model_list, best_params, \\\n",
    "                                          target_cols, model_path, cv=None)\n",
    "    print('Done.')\n",
    "    return best_refitted_models\n",
    "\n",
    "# Load all models of a type fitted on all target columns\n",
    "def load_models(model_name, X, target_cols, model_path='../pickle_objects/models/'):\n",
    "    model = {}\n",
    "    for target in target_cols:\n",
    "        file_name = '{}{}_{}_{}.pkl'.format(model_path, model_name, X, target)\n",
    "        if path.isfile(file_name):\n",
    "            print('\\tLoading {} fitted on {}... '.format(model_name, target), end='', flush=True)\n",
    "            model[target] = pickle.load(open(file_name, 'rb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('\\tDid not load {} fitted on {}: File not found in \"{}\".' \\\n",
    "                  .format(model_name, target, file_name))\n",
    "    return model\n",
    "\n",
    "# Load all models fitted on all target columns\n",
    "def load_all_models(model_list, data_cols, target_cols, model_path='../pickle_path/models/'):\n",
    "    print('Loading models fitted with best parameters...')\n",
    "    best_models = {}\n",
    "    X, y = data_cols\n",
    "    for model_name in model_list:\n",
    "        best_models[model_name] = load_models(model_name, X, target_cols, model_path)\n",
    "    print('Done.')\n",
    "    return best_models\n",
    "\n",
    "# Predict labels and probabilities for all models for all target columns\n",
    "def predict_labels_and_probas(fitted_models, model_list, X, target_cols):\n",
    "    probabilities, predictions = {}, {}\n",
    "    for model in model_list:\n",
    "        print('\\tPredicting labels and probabilities for {}...'.format(model))\n",
    "        probabilities[model], predictions[model] = {}, {}\n",
    "        for target in target_cols:\n",
    "            print('\\t\\tPredicting for {}... '.format(target), end='', flush=True)\n",
    "            probabilities[model][target] = fitted_models[model][target].predict_proba(X)[:,1]\n",
    "            predictions[model][target] = fitted_models[model][target].predict(X)\n",
    "            print('Done.')\n",
    "        print('\\tDone.')\n",
    "    return probabilities, predictions\n",
    "\n",
    "# Plot ROC curves for all models / target columns\n",
    "def plot_model_roc_curves(y_test, probabilities, model_list, target_cols, vec='countvec', \\\n",
    "                          plot_type='model', features='_features', plots_path='../plots/', force=False):\n",
    "    aucs = {}\n",
    "    # Plot by model\n",
    "    if plot_type == 'model':\n",
    "        for model in model_list:\n",
    "            print('\\tPlotting ROC curve for {}...'.format(model))\n",
    "            aucs[model] = {}\n",
    "            plt.figure(figsize=(5,4))\n",
    "            for target in target_cols:\n",
    "                fpr, tpr, threshold = roc_curve(y_test[target], probabilities[model][target])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                aucs[model][target] = auc_value\n",
    "                plt.plot(fpr, tpr, label='{}: {:0.3f}'.format('auc{}_'.format(features)+target, auc_value))\n",
    "            plt.xlabel('fpr')\n",
    "            plt.ylabel('tpr')\n",
    "            plt.title('ROC Curve for {}{} with {}'.format(model, features, vec))\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend(loc=4)\n",
    "            file_path = plots_path+'roc_'+model+'_'+vec+features+'.jpg'\n",
    "            if force or not path.isfile(file_path):\n",
    "                print('\\tDumping ROC plot to {}... '.format(file_path), end='', flush=True)\n",
    "                plt.savefig(file_path)\n",
    "                print('Done.')\n",
    "            else:\n",
    "                print('\\tDid not dump ROC plot: File already exists in \"{}\".'.format(file_path))\n",
    "            plt.close('all')\n",
    "            print('\\tDone.')\n",
    "    # Plot by target column\n",
    "    elif plot_type == 'target':\n",
    "        for target in target_cols:\n",
    "            print('\\tPlotting ROC curve for {}...'.format(target))\n",
    "            aucs[target] = {}\n",
    "            plt.figure(figsize=(5,4))\n",
    "            for model in model_list:\n",
    "                fpr, tpr, threshold = roc_curve(y_test[target], probabilities[model][target])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                aucs[target][model] = auc_value\n",
    "                plt.plot(fpr, tpr, label='{}: {:0.3f}'.format('auc{}_'.format(features)+model, auc_value))\n",
    "            plt.xlabel('fpr')\n",
    "            plt.ylabel('tpr')\n",
    "            plt.title('ROC Curve for {}{} with {}'.format(target, features, vec))\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend(loc=4)\n",
    "            file_path = plots_path+'roc_'+target+'_'+vec+features+'.jpg'\n",
    "            if force or not path.isfile(file_path):\n",
    "                print('\\tDumping ROC plot to {}... '.format(file_path), end='', flush=True)\n",
    "                plt.savefig(file_path)\n",
    "                print('\\tDone.')\n",
    "            else:\n",
    "                print('\\tDid not dump ROC plot: File already exists in \"{}\".'.format(file_path))\n",
    "            plt.close('all')\n",
    "            print('\\tDone.')\n",
    "    else:\n",
    "        raise ValueError(\"Parameter 'plot_type' must be one of 'model' or 'target'.\")\n",
    "    return aucs\n",
    "\n",
    "# Generate mean column-wise AUC for all models\n",
    "def get_mean_auc(aucs, model_list=None, target_cols=None, plot_type='model'):\n",
    "    print('\\tComputing mean AUCs... ', end='', flush=True)\n",
    "    mean_aucs = {}\n",
    "    # Compute mean auc by model\n",
    "    columns = model_list if plot_type == 'model' else target_cols\n",
    "    for col in columns:\n",
    "        mean_aucs[col] = np.mean(list(aucs[col].values()))\n",
    "    print('Done.')\n",
    "    return mean_aucs\n",
    "\n",
    "# Generate a summary AUCs dataframe for all models vs. all target columns\n",
    "def get_aucs_df(aucs, model_list, target_cols, plot_type='model'):\n",
    "    print('\\tGenerating AUCs DataFrame... ', end='', flush=True)\n",
    "    aucs_df = pd.DataFrame.from_dict(aucs)\n",
    "    aucs_df['mean'] = np.mean(aucs_df, axis=1)\n",
    "    aucs_df.loc['mean'] = np.mean(aucs_df, axis=0)\n",
    "    print('Done.')\n",
    "    return aucs_df\n",
    "\n",
    "# Plot all ROC curves, dump all mean column-wise AUCs, generate summary AUCs dataframe, and return final predictions\n",
    "def plot_and_dump_results(data_sets, best_refitted_models, model_list, vec, target_cols, plot_type='model', clean='_clean', \\\n",
    "                          os='', features='_features', plots_path='../plots/', pickle_path='../pickle_objects/', force=False):\n",
    "\n",
    "    probabilities, predictions = predict_labels_and_probas(best_refitted_models[vec], model_list, \\\n",
    "                                                           data_sets['X_test'+clean+os+'_'+vec+features], target_cols)\n",
    "    \n",
    "    aucs = plot_model_roc_curves(data_sets['y_test'+clean+os], probabilities, model_list, \\\n",
    "                                 target_cols, vec, plot_type, features, plots_path, force)\n",
    "\n",
    "    pretty_print(aucs)\n",
    "\n",
    "    mean_aucs = get_mean_auc(aucs, model_list, target_cols, plot_type)\n",
    "\n",
    "    pretty_print(mean_aucs)\n",
    "\n",
    "    aucs_df = get_aucs_df(aucs, model_list, target_cols, plot_type)\n",
    "    \n",
    "    print('\\tAUCs DataFrame for {}:'.format(vec))\n",
    "    print(aucs_df)\n",
    "\n",
    "    print('\\t', end='', flush=True)\n",
    "    dump_data(aucs_df, 'AUCs DataFrame', '{}aucs_{}{}.pkl'.format(pickle_path, vec, features), force)\n",
    "\n",
    "    if plot_type == 'model':\n",
    "        return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random.seed(1337)\n",
    "\n",
    "# Specify whether to use cleaned data or not\n",
    "is_clean, is_os = 1, 0\n",
    "clean = '_clean' if is_clean else ''\n",
    "os = '_os' if is_os else ''\n",
    "\n",
    "# Specify whether to use additional features\n",
    "use_features = 1\n",
    "features = '_features' if use_features else ''\n",
    "\n",
    "# Set all folder paths\n",
    "data_path = '../data/'\n",
    "pickle_path = '../pickle_objects/'\n",
    "model_path = pickle_path + 'models{}/'.format(features)\n",
    "plots_path = '../plots{}/'.format(features)\n",
    "\n",
    "# Specify initial variables\n",
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "vectorizers = ['countvec', 'tfidf']\n",
    "plot_types = ['model', 'target']\n",
    "data_cols = ['X_train', 'X_val', 'X_train_val', 'X_test', 'y_train', 'y_val', 'y_train_val', 'y_test']\n",
    "for i, col in enumerate(data_cols):\n",
    "    data_cols[i] = col + clean + os\n",
    "\n",
    "create_paths([data_path, pickle_path, model_path, plots_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all data sets\n",
    "data_sets = load_data(data_cols, data_path, clean=clean, os=os)\n",
    "\n",
    "print(data_sets['X_train'+clean+os].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print value counts for each target\n",
    "for target in target_cols:\n",
    "    print('{}:'.format(target))\n",
    "    for data in data_sets:\n",
    "        if 'y' in data:\n",
    "            value_counts = data_sets[data][target].value_counts()\n",
    "            print('{}: {:.3f}%\\t'.format(data, 100*value_counts[1]/sum(value_counts)), end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set ngram variables\n",
    "num_feats = 1000\n",
    "ngrams = 2\n",
    "\n",
    "# Load ngrams fitted on X_train (+clean+os)\n",
    "ngrams_data = load_ngrams(data_sets, 'X_train', num_feats, ngrams, vectorizers, pickle_path, clean, os)\n",
    "\n",
    "# Transform X_train_val (+clean+os) to ngrams\n",
    "data_sets = transform_to_ngrams(data_sets, ['X_train_val'+clean+os], ngrams_data, vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and add to data\n",
    "if use_features:\n",
    "    data_sets = generate_features(data_sets, data_cols, vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models to be run\n",
    "model_list = {\n",
    "    'bnb': BernoulliNB(),\n",
    "    'lrl1': LogisticRegression(penalty='l1'),\n",
    "    'lrl2': LogisticRegression(penalty='l2'),\n",
    "    'nbsvm': NBSVMClassifier(dual=True),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier()\n",
    "}\n",
    "\n",
    "# Specify corresponding parameters for GridSearchCV\n",
    "param_grids = {\n",
    "    'bnb': {},\n",
    "    'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1., 13., 3.)), \\\n",
    "                                  np.logspace(1., 6., num=6, endpoint=True, base=10)))},\n",
    "    'lrl2': {'C': np.concatenate((np.reciprocal(np.arange(1., 13., 3.)), \\\n",
    "                                  np.logspace(1., 6., num=6, endpoint=True, base=10)))},\n",
    "    'nbsvm': {'C': np.concatenate((np.reciprocal(np.arange(1., 13., 3.)), \\\n",
    "                                  np.logspace(1., 6., num=6, endpoint=True, base=10)))},\n",
    "    'rf': {\n",
    "        'n_estimators': np.arange(50, 550, 50),\n",
    "        'max_features': ['auto', 'log2'],\n",
    "        'max_depth': np.arange(3, 17, 2)\n",
    "    },\n",
    "    'xgb': {\n",
    "        'n_estimators': np.arange(50, 550, 50),\n",
    "        'max_depth': np.arange(3, 17, 2),\n",
    "        'learning_rate': [1e-1, 1e-3, 1e-5],\n",
    "        'reg_lambda': [1e-1, 1, 10, 50]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predefined split for CV\n",
    "# 0 corresponds to val, -1 to train\n",
    "val_fold = [-1]*len(data_sets['X_train'+clean+os]) + [0]*len(data_sets['X_val'+clean+os])\n",
    "predefined_split = PredefinedSplit(test_fold=val_fold)\n",
    "\n",
    "# Find best hyperparameter settings for each data set for each model\n",
    "best_models = {}\n",
    "for vec in vectorizers:\n",
    "    print('Running for {}...'.format(vec))\n",
    "    data_cols = ('X_train_val'+clean+os+'_'+vec+features, 'y_train_val'+clean+os)\n",
    "    best_models[vec] = fit_all_models(data_sets, data_cols, model_list, param_grids, \\\n",
    "                                      target_cols, model_path, cv=predefined_split)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ngrams fitted on X_train_val (+clean+os)\n",
    "ngrams_data = load_ngrams(data_sets, 'X_train_val', num_feats, ngrams, vectorizers, pickle_path, clean, os)\n",
    "\n",
    "# Transform X_train_val and X_test (+clean+os) to ngrams\n",
    "data_sets = transform_to_ngrams(data_sets, ['X_train_val'+clean+os, 'X_test'+clean+os], \\\n",
    "                                ngrams_data, vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and add to data\n",
    "if use_features:\n",
    "    data_sets = generate_features(data_sets, data_cols, vectorizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refit all models with best parameters on ngrams fitted on X_train_val (+clean+os)\n",
    "best_refitted_models = {}\n",
    "for vec in vectorizers:\n",
    "    print('\\nRunning for {}...'.format(vec))\n",
    "    data_cols = ('X_train_val'+clean+os+'_'+vec+features, 'y_train_val'+clean+os)\n",
    "    best_refitted_models[vec] = refit_best_models(data_sets, model_list, data_cols, \\\n",
    "                                                  best_models[vec], target_cols, model_path)\n",
    "    # Load models if already fitted and dumped\n",
    "    # best_refitted_models[vec] = load_all_models(model_list, data_cols, target_cols, model_path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities, predictions = {}, {} # Store probabilities and predictions for all models\n",
    "\n",
    "# Plot all ROC curves, dump all mean column-wise AUCs, generate summary AUCs dataframe, and get final predictions\n",
    "for plot_type in plot_types:\n",
    "    for vec in vectorizers:\n",
    "        print('Generating results for {}...'.format(vec))\n",
    "        if plot_type == 'model':\n",
    "            probabilities[vec], predictions[vec] = plot_and_dump_results(data_sets, best_refitted_models, model_list, vec, target_cols, \\\n",
    "                                                     plot_type, clean, os, features, plots_path, pickle_path)\n",
    "        else:\n",
    "            plot_and_dump_results(data_sets, best_refitted_models, model_list, vec, target_cols, \\\n",
    "                                  plot_type, clean, os, features, plots_path, pickle_path)\n",
    "        print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump all final probabilities and predictions\n",
    "dump_data(probabilities, 'Probabilities', pickle_path+'probabilities{}.pkl'.format(features))\n",
    "dump_data(predictions, 'Predictions', pickle_path+'predictions{}.pkl'.format(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
