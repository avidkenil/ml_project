{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from os import path, makedirs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(is_clean=0, is_os=0):\n",
    "    clean = '_clean' if is_clean else ''\n",
    "    os = '_os' if is_os else ''\n",
    "    data_sets = {}\n",
    "    data_cols = [\n",
    "        'data', 'X_train', 'X_val', 'X_train_val', 'X_test', \\\n",
    "        'y_train', 'y_val', 'y_train_val', 'y_test'\n",
    "    ]\n",
    "    \n",
    "    for i, col in enumerate(data_cols):\n",
    "        data_cols[i] = col + clean + os\n",
    "    \n",
    "    for col in data_cols:\n",
    "        data_sets[col] = pickle.load(open('../data/{}.pkl'.format(col),'rb'))\n",
    "    \n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_clean, is_os = 1, 0\n",
    "clean, os = '_clean', ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = load_data(is_clean=1, is_os=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>explanation edit username hardcore metallica f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>d'aww match background colour -pron- seemingly...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>hey man -pron- not try edit war -pron- guy con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>not real suggestion improvement wonder section...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>congratulations good use tool good · talk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>cocksucker piss work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>vandalism matt shirvington article revert not ban</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>sorry word nonsense offensive -pron- not inten...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment subject contrary dulithgow</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  explanation edit username hardcore metallica f...      0   \n",
       "1  000103f0d9cfb60f  d'aww match background colour -pron- seemingly...      0   \n",
       "2  000113f07ec002fd  hey man -pron- not try edit war -pron- guy con...      0   \n",
       "3  0001b41b1c6bb37e  not real suggestion improvement wonder section...      0   \n",
       "4  0001d958c54c6e35                      sir hero chance remember page      0   \n",
       "5  00025465d4725e87          congratulations good use tool good · talk      0   \n",
       "6  0002bcb3da6cb337                               cocksucker piss work      1   \n",
       "7  00031b1e95af7921  vandalism matt shirvington article revert not ban      0   \n",
       "8  00037261f536c51d  sorry word nonsense offensive -pron- not inten...      0   \n",
       "9  00040093b2687caa               alignment subject contrary dulithgow      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['data'+clean+os].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101689</th>\n",
       "      <td>202d64bd4c2bd9a4</td>\n",
       "      <td>champion hurdle delighted use 1 2_3 image uplo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26429</th>\n",
       "      <td>4601831cd03ec679</td>\n",
       "      <td>edit war currently appear engage edit war note...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62499</th>\n",
       "      <td>a73c6f5b69d963be</td>\n",
       "      <td>-pron- wrong bud ready use taran boi verdict n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>1ad558921b36c611</td>\n",
       "      <td>attempt change las vegas season las vegas augu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16254</th>\n",
       "      <td>2adc0c27c1165eef</td>\n",
       "      <td>people arab homosexual bad thing d**n f***in h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text\n",
       "101689  202d64bd4c2bd9a4  champion hurdle delighted use 1 2_3 image uplo...\n",
       "26429   4601831cd03ec679  edit war currently appear engage edit war note...\n",
       "62499   a73c6f5b69d963be  -pron- wrong bud ready use taran boi verdict n...\n",
       "10145   1ad558921b36c611  attempt change las vegas season las vegas augu...\n",
       "16254   2adc0c27c1165eef  people arab homosexual bad thing d**n f***in h..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['X_train'+clean+os].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic:\n",
      "y_train_clean: 9.528%\ty_val_clean: 9.551%\ty_train_val_clean: 9.533%\ty_test_clean: 9.789%\t\n",
      "\n",
      "severe_toxic:\n",
      "y_train_clean: 1.005%\ty_val_clean: 0.993%\ty_train_val_clean: 1.002%\ty_test_clean: 0.990%\t\n",
      "\n",
      "obscene:\n",
      "y_train_clean: 5.321%\ty_val_clean: 5.274%\ty_train_val_clean: 5.309%\ty_test_clean: 5.239%\t\n",
      "\n",
      "threat:\n",
      "y_train_clean: 0.287%\ty_val_clean: 0.295%\ty_train_val_clean: 0.289%\ty_test_clean: 0.342%\t\n",
      "\n",
      "insult:\n",
      "y_train_clean: 4.960%\ty_val_clean: 4.860%\ty_train_val_clean: 4.935%\ty_test_clean: 4.941%\t\n",
      "\n",
      "identity_hate:\n",
      "y_train_clean: 0.902%\ty_val_clean: 0.833%\ty_train_val_clean: 0.885%\ty_test_clean: 0.862%\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print value counts for each target\n",
    "for col in target_cols:\n",
    "    print('{}:'.format(col))\n",
    "    for data in data_sets:\n",
    "        if 'y' in data:\n",
    "            value_counts = data_sets[data][col].value_counts()\n",
    "            print('{}: {:.3f}%\\t'.format(data, 100*value_counts[1]/sum(value_counts)), end='')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = '../pickle_objects/'\n",
    "if not path.exists(pickle_path):\n",
    "    makedirs(pickle_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_feats = 1000\n",
    "n_grams = 2\n",
    "ngram_range = list(map(lambda x: x+1,range(n_grams)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ngrams(data, num_feats, ngram_range, is_clean=1, is_os=0):\n",
    "    clean = '_clean' if is_clean else ''\n",
    "    os = '_os' if is_os else ''\n",
    "    ngrams = {}\n",
    "    vec_params = {'analyzer': 'word', 'lowercase': True,'max_features': num_feats, 'ngram_range': ngram_range}\n",
    "    \n",
    "    for vec in ['countvec', 'tfidf']:\n",
    "        # Load vectorizer if present\n",
    "        file_name = '{}{}_{}_ngrams_{}{}.pkl'.format(pickle_path, vec, num_feats, n_grams, clean+os)\n",
    "        if path.isfile(file_name):\n",
    "            ngrams[vec] = pickle.load(open(file_name, 'rb'))\n",
    "        else:\n",
    "            # Fit, store, and load vectorizer\n",
    "            ngrams_vec = CountVectorizer(**vec_params) if vec == 'countvec' else TfidfVectorizer(**vec_params)\n",
    "            ngrams_vec.fit(data['comment_text'])\n",
    "            ngrams[vec] = ngrams_vec\n",
    "            pickle.dump(ngrams_vec, open(file_name, 'wb'))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range, is_clean, is_os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_ngrams(data_set, data_cols, ngrams):\n",
    "    for data in data_cols:\n",
    "        for vec in ['countvec', 'tfidf']:\n",
    "            data_sets[data+'_'+vec] = ngrams[vec].transform(data_sets[data]['comment_text'])\n",
    "    return data_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets = transform_to_ngrams(data_sets, ['X_train_val'+clean+os, 'X_test'+clean+os], ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    scaler = StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X, y, params, scoring='roc_auc', cv=None):\n",
    "    print(model)\n",
    "    models = BinaryRelevance(model)\n",
    "    if cv:\n",
    "        models = GridSearchCV(models, params, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "        models.fit(X, y)\n",
    "        return models.best_model_, models.best_params_, models.best_score_\n",
    "    else:\n",
    "        models.fit(X, y)\n",
    "        return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_all_models(data_sets, data_cols, model_list, param_grids, cv=None):\n",
    "    best_models, best_params, best_scores = {}, {}, {}\n",
    "    for (X, y) in data_cols:\n",
    "        for model in model_list:\n",
    "            if cv:\n",
    "                best_models[X][model], best_params[X][model], best_scores[X][model] = \\\n",
    "                fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model], \\\n",
    "                          scoring='roc_auc', cv=cv)\n",
    "            else:\n",
    "                best_models[X][model] = \\\n",
    "                fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model], \\\n",
    "                          scoring='roc_auc', cv=cv)\n",
    "    if cv:\n",
    "        return best_models, best_params, best_scores\n",
    "    return best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels_and_probas(model, X):\n",
    "    predictions = model.predict_proba(X)\n",
    "    probabilities = np.squeeze(np.asarray(predictions.todense()))\n",
    "    return predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = {\n",
    "    'bnb': BernoulliNB(),\n",
    "    'gnb': GaussianNB(),\n",
    "    'lrl1': LogisticRegression(penalty='l1'),\n",
    "    'lrl2': LogisticRegression(penalty='l2'),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier(),\n",
    "    'svm': SVC(kernel='linear')\n",
    "}\n",
    "    \n",
    "param_grids = {\n",
    "    'bnb': {},\n",
    "    'gnb': {},\n",
    "    'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1, 13, 3)), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "    'lrl2': {'C': np.concatenate((np.reciprocal(np.arange(1, 13, 3)), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "    'rf': {\n",
    "        'n_estimators': np.arange(50, 250, 50),\n",
    "        'max_features': ['auto', 'log2'],\n",
    "        'max_depth': np.arange(3, 13, 2)\n",
    "    },\n",
    "    'xgb': {'n_estimators': [1]},\n",
    "    'svm': {'C': np.concatenate((np.arange(1, 13, 3), np.logspace(1, 6, num=6, endpoint=True, base=10)))},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set predefined split for CV\n",
    "# 0 corresponds to val, -1 to train\n",
    "val_fold = [-1]*len(data_sets['X_train'+clean+os]) + [0]*len(data_sets['X_val'+clean+os])\n",
    "predefined_split = PredefinedSplit(test_fold=val_fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f211cd99270, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f211cd99270, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    107         except (RuntimeError, AssertionError):\n    108             old_loop = None\n    109         try:\n    110             self._setup_logging()\n    111             asyncio.set_event_loop(self.asyncio_loop)\n--> 112             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    113         finally:\n    114             asyncio.set_event_loop(old_loop)\n    115 \n    116     def stop(self):\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    416             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    417                                    finalizer=self._asyncgen_finalizer_hook)\n    418         try:\n    419             events._set_running_loop(self)\n    420             while True:\n--> 421                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    422                 if self._stopping:\n    423                     break\n    424         finally:\n    425             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1421                         logger.warning('Executing %s took %.3f seconds',\n   1422                                        _format_handle(handle), dt)\n   1423                 finally:\n   1424                     self._current_handle = None\n   1425             else:\n-> 1426                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(13, 1)>>\n   1427         handle = None  # Needed to break cycles when an exception occurs.\n   1428 \n   1429     def _set_coroutine_wrapper(self, enabled):\n   1430         try:\n\n...........................................................................\n/usr/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(13, 1)>)\n    122             self._callback = None\n    123             self._args = None\n    124 \n    125     def _run(self):\n    126         try:\n--> 127             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (13, 1)\n    128         except Exception as exc:\n    129             cb = _format_callback_source(self._callback, self._args)\n    130             msg = 'Exception in callback {}'.format(cb)\n    131             context = {\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=13, events=1)\n     97             self.writers.remove(fd)\n     98         del self.handlers[fd]\n     99 \n    100     def _handle_events(self, fd, events):\n    101         fileobj, handler_func = self.handlers[fd]\n--> 102         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    103 \n    104     def start(self):\n    105         try:\n    106             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'16413b7e67c34e4c913bd760ce4a4bdc']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'16413b7e67c34e4c913bd760ce4a4bdc'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-37-292e8c033f66>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>\n        result = <ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>, result=<ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'BinaryRelevance': <class 'skmultilearn.problem_transform.br.BinaryRelevance'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ra..._ipython().run_line_magic('matplotlib', 'inline')\", 'from sklearn.model_selection import train_test_s...ssifier\\nfrom xgboost.sklearn import XGBClassifier', '# Set random seed\\nrandom.seed(1337)', \"def load_data(is_clean=0, is_os=0):\\n    clean = ...pkl'.format(col),'rb'))\\n    \\n    return data_sets\", \"is_clean, is_os = 1, 0\\nclean, os = '_clean', ''\", 'data_sets = load_data(is_clean=1, is_os=0)', \"target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\", \"data_sets['data'+clean+os].head(10)\", \"data_sets['X_train'+clean+os].head()\", \"# Print value counts for each target\\nfor col in ...ts[1]/sum(value_counts)), end='')\\n    print('\\\\n')\", \"pickle_path = '../pickle_objects/'\\nif not path.exists(pickle_path):\\n    makedirs(pickle_path)\", 'num_feats = 1000\\nn_grams = 2\\nngram_range = list(map(lambda x: x+1,range(n_grams)))', \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {8:                  id                             ...      0        0       0       0              0  , 9:                       id                        ...people arab homosexual bad thing d**n f***in h...}, 'PredefinedSplit': <class 'sklearn.model_selection._split.PredefinedSplit'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'BinaryRelevance': <class 'skmultilearn.problem_transform.br.BinaryRelevance'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ra..._ipython().run_line_magic('matplotlib', 'inline')\", 'from sklearn.model_selection import train_test_s...ssifier\\nfrom xgboost.sklearn import XGBClassifier', '# Set random seed\\nrandom.seed(1337)', \"def load_data(is_clean=0, is_os=0):\\n    clean = ...pkl'.format(col),'rb'))\\n    \\n    return data_sets\", \"is_clean, is_os = 1, 0\\nclean, os = '_clean', ''\", 'data_sets = load_data(is_clean=1, is_os=0)', \"target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\", \"data_sets['data'+clean+os].head(10)\", \"data_sets['X_train'+clean+os].head()\", \"# Print value counts for each target\\nfor col in ...ts[1]/sum(value_counts)), end='')\\n    print('\\\\n')\", \"pickle_path = '../pickle_objects/'\\nif not path.exists(pickle_path):\\n    makedirs(pickle_path)\", 'num_feats = 1000\\nn_grams = 2\\nngram_range = list(map(lambda x: x+1,range(n_grams)))', \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {8:                  id                             ...      0        0       0       0              0  , 9:                       id                        ...people arab homosexual bad thing d**n f***in h...}, 'PredefinedSplit': <class 'sklearn.model_selection._split.PredefinedSplit'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-37-292e8c033f66> in <module>()\n      5 param_grids = {\n      6     'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1, 4, 3)), np.logspace(1, 2, num=2, \\\n      7                                                                                  endpoint=True, base=10)))}\n      8 }\n      9 \n---> 10 fit_all_models(data_sets, [('X_train'+clean+os, 'y_train'+clean+os)], model_list,                param_grids, cv=predefined_split)\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-34-38d68be09502> in fit_all_models(data_sets={'X_test_clean':                       id                        ...ove content talk pag...\n\n[31915 rows x 2 columns], 'X_test_clean_countvec': <31915x1000 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'X_test_clean_tfidf': <31915x1000 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'X_train_clean':                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], 'X_train_val_clean':                       id                        ...ounty texas|of head...\n\n[127656 rows x 2 columns], 'X_train_val_clean_countvec': <127656x1000 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'X_train_val_clean_tfidf': <127656x1000 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'X_val_clean':                       id                        ...    -pron- right remove\n\n[31914 rows x 2 columns], 'data_clean':                       id                        ...    0              0  \n\n[159571 rows x 8 columns], 'y_test_clean':         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[31915 rows x 6 columns], ...}, data_cols=[('X_train_clean', 'y_train_clean')], model_list={'lrl1': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False)}, param_grids={'lrl1': {'C': array([  1.,  10., 100.])}}, cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))\n      1 def fit_all_models(data_sets, data_cols, model_list, param_grids, cv=None):\n      2     best_models, best_params, best_scores = {}, {}, {}\n      3     for (X, y) in data_cols:\n      4         for model in model_list:\n      5             if cv:\n----> 6                 best_models[X][model], best_params[X][model], best_scores[X][model] =                 fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model],                           scoring='roc_auc', cv=cv)\n      7             else:\n      8                 best_models[X][model] =                 fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model],                           scoring='roc_auc', cv=cv)\n      9     if cv:\n     10         return best_models, best_params, best_scores\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-36-c365f5705cf9> in fit_model(model=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], params={'C': array([  1.,  10., 100.])}, scoring='roc_auc', cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))\n      1 def fit_model(model, X, y, params, scoring='roc_auc', cv=None):\n      2     print(model)\n      3     models = BinaryRelevance(model)\n      4     if cv:\n      5         models = GridSearchCV(models, params, cv=cv, scoring=scoring, n_jobs=-1)\n----> 6         models.fit(X, y)\n      7         return models.best_model_, models.best_params_, models.best_score_\n      8     else:\n      9         models.fit(X, y)\n     10         return models\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=PredefinedSplit(test_fold=array(...core='warn',\n       scoring='roc_auc', verbose=0), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method PredefinedSplit.split of PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0]))>\n        X =                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns]\n        y =         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue May  1 21:57:34 2018\nPID: 24283                             Python 3.6.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 95739, 95740, 95741]), test=array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), verbose=0, parameters={'C': 1.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method MLClassifierBase.set_params of Bin...tart=False),\n        require_dense=[True, True])>\n        parameters = {'C': 1.0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/skmultilearn/base/base.py in set_params(self=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), **parameters={'C': 1.0})\n    228                 setattr(self, parameter, value)\n    229             else:\n    230                 raise ValueError('Invalid parameter %s for estimator %s. '\n    231                                  'Check the list of available parameters '\n    232                                  'with `estimator.get_params().keys()`.' %\n--> 233                                  (parameter, self))\n        parameter = 'C'\n        self = BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True])\n    234 \n    235 \n    236         parameters_below_current_level = [x for x in parameters if '__' in x]\n    237         parameters_grouped_by_current_level = {object : {} for object in valid_params}\n\nValueError: Invalid parameter C for estimator BinaryRelevance(classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n        require_dense=[True, True]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"/usr/local/lib/python3.6/dist-packages/skmultilearn/base/base.py\", line 233, in set_params\n    (parameter, self))\nValueError: Invalid parameter C for estimator BinaryRelevance(classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n        require_dense=[True, True]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue May  1 21:57:34 2018\nPID: 24283                             Python 3.6.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 95739, 95740, 95741]), test=array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), verbose=0, parameters={'C': 1.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method MLClassifierBase.set_params of Bin...tart=False),\n        require_dense=[True, True])>\n        parameters = {'C': 1.0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/skmultilearn/base/base.py in set_params(self=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), **parameters={'C': 1.0})\n    228                 setattr(self, parameter, value)\n    229             else:\n    230                 raise ValueError('Invalid parameter %s for estimator %s. '\n    231                                  'Check the list of available parameters '\n    232                                  'with `estimator.get_params().keys()`.' %\n--> 233                                  (parameter, self))\n        parameter = 'C'\n        self = BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True])\n    234 \n    235 \n    236         parameters_below_current_level = [x for x in parameters if '__' in x]\n    237         parameters_grouped_by_current_level = {object : {} for object in valid_params}\n\nValueError: Invalid parameter C for estimator BinaryRelevance(classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n        require_dense=[True, True]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue May  1 21:57:34 2018\nPID: 24283                             Python 3.6.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 95739, 95740, 95741]), test=array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), verbose=0, parameters={'C': 1.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method MLClassifierBase.set_params of Bin...tart=False),\n        require_dense=[True, True])>\n        parameters = {'C': 1.0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/skmultilearn/base/base.py in set_params(self=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), **parameters={'C': 1.0})\n    228                 setattr(self, parameter, value)\n    229             else:\n    230                 raise ValueError('Invalid parameter %s for estimator %s. '\n    231                                  'Check the list of available parameters '\n    232                                  'with `estimator.get_params().keys()`.' %\n--> 233                                  (parameter, self))\n        parameter = 'C'\n        self = BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True])\n    234 \n    235 \n    236         parameters_below_current_level = [x for x in parameters if '__' in x]\n    237         parameters_grouped_by_current_level = {object : {} for object in valid_params}\n\nValueError: Invalid parameter C for estimator BinaryRelevance(classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n        require_dense=[True, True]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-292e8c033f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m }\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfit_all_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_sets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'X_train'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y_train'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mclean\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m,\u001b[0m                \u001b[0mparam_grids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredefined_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-38d68be09502>\u001b[0m in \u001b[0;36mfit_all_models\u001b[0;34m(data_sets, data_cols, model_list, param_grids, cv)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 \u001b[0mbest_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                 \u001b[0mbest_models\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m                 \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_sets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                           \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-c365f5705cf9>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, X, y, params, scoring, cv)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmodels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_model_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f211cd99270, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f211cd99270, file \"/...3.6/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.6/dist-packages/__pycache__/ipykernel_launcher.cpython-36.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...b/python3.6/dist-packages/ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    107         except (RuntimeError, AssertionError):\n    108             old_loop = None\n    109         try:\n    110             self._setup_logging()\n    111             asyncio.set_event_loop(self.asyncio_loop)\n--> 112             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    113         finally:\n    114             asyncio.set_event_loop(old_loop)\n    115 \n    116     def stop(self):\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    416             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    417                                    finalizer=self._asyncgen_finalizer_hook)\n    418         try:\n    419             events._set_running_loop(self)\n    420             while True:\n--> 421                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    422                 if self._stopping:\n    423                     break\n    424         finally:\n    425             self._stopping = False\n\n...........................................................................\n/usr/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1421                         logger.warning('Executing %s took %.3f seconds',\n   1422                                        _format_handle(handle), dt)\n   1423                 finally:\n   1424                     self._current_handle = None\n   1425             else:\n-> 1426                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(13, 1)>>\n   1427         handle = None  # Needed to break cycles when an exception occurs.\n   1428 \n   1429     def _set_coroutine_wrapper(self, enabled):\n   1430         try:\n\n...........................................................................\n/usr/lib/python3.6/asyncio/events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(13, 1)>)\n    122             self._callback = None\n    123             self._args = None\n    124 \n    125     def _run(self):\n    126         try:\n--> 127             self._callback(*self._args)\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (13, 1)\n    128         except Exception as exc:\n    129             cb = _format_callback_source(self._callback, self._args)\n    130             msg = 'Exception in callback {}'.format(cb)\n    131             context = {\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/platform/asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=13, events=1)\n     97             self.writers.remove(fd)\n     98         del self.handlers[fd]\n     99 \n    100     def _handle_events(self, fd, events):\n    101         fileobj, handler_func = self.handlers[fd]\n--> 102         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    103 \n    104     def start(self):\n    105         try:\n    106             old_loop = asyncio.get_event_loop()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'16413b7e67c34e4c913bd760ce4a4bdc']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'16413b7e67c34e4c913bd760ce4a4bdc'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 2, 1, 57, 33, 682589, tzinfo=tzutc()), 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'session': '16413b7e67c34e4c913bd760ce4a4bdc', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '58c02700189c4711b7c27349ecf83d1f', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = \"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\"\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\",), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\",)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=\"model_list = {\\n    'lrl1': LogisticRegression(pe...\\n               param_grids, cv=predefined_split)\", store_history=True, silent=False, shell_futures=True)\n   2723                 self.displayhook.exec_result = result\n   2724 \n   2725                 # Execute the user code\n   2726                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2727                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2728                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2729                 \n   2730                 self.last_execution_succeeded = not has_raised\n   2731                 self.last_execution_result = result\n   2732 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>], cell_name='<ipython-input-37-292e8c033f66>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>)\n   2851                     return True\n   2852 \n   2853             for i, node in enumerate(to_run_interactive):\n   2854                 mod = ast.Interactive([node])\n   2855                 code = compiler(mod, cell_name, \"single\")\n-> 2856                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>\n        result = <ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>\n   2857                     return True\n   2858 \n   2859             # Flush softspace\n   2860             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>, result=<ExecutionResult object at 7f20b407f0f0, executi..._before_exec=None error_in_exec=None result=None>)\n   2905         outflag = True  # happens in more places, so it's easier as default\n   2906         try:\n   2907             try:\n   2908                 self.hooks.pre_run_code_hook()\n   2909                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2910                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f211484c300, file \"<ipython-input-37-292e8c033f66>\", line 10>\n        self.user_global_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'BinaryRelevance': <class 'skmultilearn.problem_transform.br.BinaryRelevance'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ra..._ipython().run_line_magic('matplotlib', 'inline')\", 'from sklearn.model_selection import train_test_s...ssifier\\nfrom xgboost.sklearn import XGBClassifier', '# Set random seed\\nrandom.seed(1337)', \"def load_data(is_clean=0, is_os=0):\\n    clean = ...pkl'.format(col),'rb'))\\n    \\n    return data_sets\", \"is_clean, is_os = 1, 0\\nclean, os = '_clean', ''\", 'data_sets = load_data(is_clean=1, is_os=0)', \"target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\", \"data_sets['data'+clean+os].head(10)\", \"data_sets['X_train'+clean+os].head()\", \"# Print value counts for each target\\nfor col in ...ts[1]/sum(value_counts)), end='')\\n    print('\\\\n')\", \"pickle_path = '../pickle_objects/'\\nif not path.exists(pickle_path):\\n    makedirs(pickle_path)\", 'num_feats = 1000\\nn_grams = 2\\nngram_range = list(map(lambda x: x+1,range(n_grams)))', \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {8:                  id                             ...      0        0       0       0              0  , 9:                       id                        ...people arab homosexual bad thing d**n f***in h...}, 'PredefinedSplit': <class 'sklearn.model_selection._split.PredefinedSplit'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n        self.user_ns = {'BernoulliNB': <class 'sklearn.naive_bayes.BernoulliNB'>, 'BinaryRelevance': <class 'skmultilearn.problem_transform.br.BinaryRelevance'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'GaussianNB': <class 'sklearn.naive_bayes.GaussianNB'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport ra..._ipython().run_line_magic('matplotlib', 'inline')\", 'from sklearn.model_selection import train_test_s...ssifier\\nfrom xgboost.sklearn import XGBClassifier', '# Set random seed\\nrandom.seed(1337)', \"def load_data(is_clean=0, is_os=0):\\n    clean = ...pkl'.format(col),'rb'))\\n    \\n    return data_sets\", \"is_clean, is_os = 1, 0\\nclean, os = '_clean', ''\", 'data_sets = load_data(is_clean=1, is_os=0)', \"target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\", \"data_sets['data'+clean+os].head(10)\", \"data_sets['X_train'+clean+os].head()\", \"# Print value counts for each target\\nfor col in ...ts[1]/sum(value_counts)), end='')\\n    print('\\\\n')\", \"pickle_path = '../pickle_objects/'\\nif not path.exists(pickle_path):\\n    makedirs(pickle_path)\", 'num_feats = 1000\\nn_grams = 2\\nngram_range = list(map(lambda x: x+1,range(n_grams)))', \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def load_ngrams(data, num_feats, ngram_range):\\n ...vec, num_feats,n_grams), 'wb'))\\n    return ngrams\", \"ngrams = load_ngrams(data_sets['X_train'+clean+os], num_feats, ngram_range)\", \"def transform_to_ngrams(data_set, data_cols, ngr..._sets[data]['comment_text'])\\n    return data_sets\", ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'Out': {8:                  id                             ...      0        0       0       0              0  , 9:                       id                        ...people arab homosexual bad thing d**n f***in h...}, 'PredefinedSplit': <class 'sklearn.model_selection._split.PredefinedSplit'>, 'RandomForestClassifier': <class 'sklearn.ensemble.forest.RandomForestClassifier'>, ...}\n   2911             finally:\n   2912                 # Reset our crash handler in place\n   2913                 sys.excepthook = old_excepthook\n   2914         except SystemExit as e:\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-37-292e8c033f66> in <module>()\n      5 param_grids = {\n      6     'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1, 4, 3)), np.logspace(1, 2, num=2, \\\n      7                                                                                  endpoint=True, base=10)))}\n      8 }\n      9 \n---> 10 fit_all_models(data_sets, [('X_train'+clean+os, 'y_train'+clean+os)], model_list,                param_grids, cv=predefined_split)\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-34-38d68be09502> in fit_all_models(data_sets={'X_test_clean':                       id                        ...ove content talk pag...\n\n[31915 rows x 2 columns], 'X_test_clean_countvec': <31915x1000 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'X_test_clean_tfidf': <31915x1000 sparse matrix of type '<class 'numpy... stored elements in Compressed Sparse Row format>, 'X_train_clean':                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], 'X_train_val_clean':                       id                        ...ounty texas|of head...\n\n[127656 rows x 2 columns], 'X_train_val_clean_countvec': <127656x1000 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'X_train_val_clean_tfidf': <127656x1000 sparse matrix of type '<class 'nump... stored elements in Compressed Sparse Row format>, 'X_val_clean':                       id                        ...    -pron- right remove\n\n[31914 rows x 2 columns], 'data_clean':                       id                        ...    0              0  \n\n[159571 rows x 8 columns], 'y_test_clean':         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[31915 rows x 6 columns], ...}, data_cols=[('X_train_clean', 'y_train_clean')], model_list={'lrl1': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False)}, param_grids={'lrl1': {'C': array([  1.,  10., 100.])}}, cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))\n      1 def fit_all_models(data_sets, data_cols, model_list, param_grids, cv=None):\n      2     best_models, best_params, best_scores = {}, {}, {}\n      3     for (X, y) in data_cols:\n      4         for model in model_list:\n      5             if cv:\n----> 6                 best_models[X][model], best_params[X][model], best_scores[X][model] =                 fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model],                           scoring='roc_auc', cv=cv)\n      7             else:\n      8                 best_models[X][model] =                 fit_model(model_list[model], data_sets[X], data_sets[y], param_grids[model],                           scoring='roc_auc', cv=cv)\n      9     if cv:\n     10         return best_models, best_params, best_scores\n\n...........................................................................\n/home/mihir/Desktop/GitHub/nyu/ml_project/src/<ipython-input-36-c365f5705cf9> in fit_model(model=LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], params={'C': array([  1.,  10., 100.])}, scoring='roc_auc', cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])))\n      1 def fit_model(model, X, y, params, scoring='roc_auc', cv=None):\n      2     print(model)\n      3     models = BinaryRelevance(model)\n      4     if cv:\n      5         models = GridSearchCV(models, params, cv=cv, scoring=scoring, n_jobs=-1)\n----> 6         models.fit(X, y)\n      7         return models.best_model_, models.best_params_, models.best_score_\n      8     else:\n      9         models.fit(X, y)\n     10         return models\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=PredefinedSplit(test_fold=array(...core='warn',\n       scoring='roc_auc', verbose=0), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], groups=None, **fit_params={})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method PredefinedSplit.split of PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0]))>\n        X =                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns]\n        y =         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns]\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue May  1 21:57:34 2018\nPID: 24283                             Python 3.6.3: /usr/local/bin/python3\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]),                       id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns],         toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], {'score': make_scorer(roc_auc_score, needs_threshold=True)}, array([    0,     1,     2, ..., 95739, 95740, 95741]), array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), 0, {'C': 1.0})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), X=                      id                        ...e bill gates1.jpg va...\n\n[95742 rows x 2 columns], y=        toxic  severe_toxic  obscene  threat  in...       0              0\n\n[95742 rows x 6 columns], scorer={'score': make_scorer(roc_auc_score, needs_threshold=True)}, train=array([    0,     1,     2, ..., 95739, 95740, 95741]), test=array([ 95742,  95743,  95744, ..., 127653, 127654, 127655]), verbose=0, parameters={'C': 1.0}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method MLClassifierBase.set_params of Bin...tart=False),\n        require_dense=[True, True])>\n        parameters = {'C': 1.0}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\n/usr/local/lib/python3.6/dist-packages/skmultilearn/base/base.py in set_params(self=BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True]), **parameters={'C': 1.0})\n    228                 setattr(self, parameter, value)\n    229             else:\n    230                 raise ValueError('Invalid parameter %s for estimator %s. '\n    231                                  'Check the list of available parameters '\n    232                                  'with `estimator.get_params().keys()`.' %\n--> 233                                  (parameter, self))\n        parameter = 'C'\n        self = BinaryRelevance(classifier=LogisticRegression(C=...start=False),\n        require_dense=[True, True])\n    234 \n    235 \n    236         parameters_below_current_level = [x for x in parameters if '__' in x]\n    237         parameters_grouped_by_current_level = {object : {} for object in valid_params}\n\nValueError: Invalid parameter C for estimator BinaryRelevance(classifier=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n          verbose=0, warm_start=False),\n        require_dense=[True, True]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "model_list = {\n",
    "    'lrl1': LogisticRegression(penalty='l1')\n",
    "}\n",
    "    \n",
    "param_grids = {\n",
    "    'lrl1': {'C': np.concatenate((np.reciprocal(np.arange(1, 4, 3)), np.logspace(1, 2, num=2, \\\n",
    "                                                                                 endpoint=True, base=10)))}\n",
    "}\n",
    "\n",
    "fit_all_models(data_sets, [('X_train'+clean+os, 'y_train'+clean+os)], model_list, \\\n",
    "               param_grids, cv=predefined_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit individual BernoulliNB models for each target with Count Vectorizer\n",
    "bnb_countvec = BinaryRelevance(BernoulliNB())\n",
    "bnb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "predictions_bnb_countvec = bnb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit individual GaussianNB models for each target with Count Vectorizer\n",
    "gnb_countvec = BinaryRelevance(GaussianNB())\n",
    "gnb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "predictions_gnb_countvec = gnb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit individual GaussianNB models for each target with TF-IDF Vectorizer\n",
    "gnb_tfidf = BinaryRelevance(GaussianNB())\n",
    "gnb_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_gnb_tfidf = gnb_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit individual Logistic Regression+l1 models for each target with TF-IDF Vectorizer\n",
    "lr1_tfidf = BinaryRelevance(LogisticRegression(penalty='l1'))\n",
    "lr1_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_lr1_tfidf = lr1_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit individual Logistic Regression+l2 models for each target with TF-IDF Vectorizer\n",
    "lr2_tfidf = BinaryRelevance(LogisticRegression(penalty='l2'))\n",
    "lr2_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "predictions_lr2_tfidf = lr2_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# Fit RandomForestClassifier for each target with Count Vectorizer\n",
    "rf_countvec = RandomForestClassifier(n_estimators=100)\n",
    "rf_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "probabilities_rf_countvec = rf_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# Fit RandomForestClassifier for each target with TF-IDF Vectorizer\n",
    "rf_tfidf = RandomForestClassifier(n_estimators=100)\n",
    "rf_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "probabilities_rf_tfidf = rf_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "# # Fit XGBClassifier for each target with Count Vectorizer\n",
    "# xgb_countvec = BinaryRelevance(XGBClassifier(n_estimators=1))\n",
    "# xgb_countvec.fit(X_train_val_countvec, y_train_val)\n",
    "# predictions_xgb_countvec = xgb_countvec.predict_proba(X_test_countvec)\n",
    "\n",
    "# # Fit XGBClassifier for each target with TF-IDF Vectorizer\n",
    "# xgb_tfidf = BinaryRelevance(XGBClassifier(n_estimators=1))\n",
    "# xgb_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "# predictions_xgb_tfidf = xgb_tfidf.predict_proba(X_test_tfidf)\n",
    "\n",
    "\n",
    "# # Fit individual GaussianNB models for each target with TF-IDF Vectorizer\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train_val_tfidf)\n",
    "# X_train_val_tfidf = scaler.transform(X_train_val_tfidf)\n",
    "# X_test_tfidf = scaler.transform(X_test_tfidf)\n",
    "# svc_tfidf = BinaryRelevance(SVC(kernel='linear'))\n",
    "# svc_tfidf.fit(X_train_val_tfidf, y_train_val)\n",
    "# predictions_svc_tfidf = svc_tfidf.predict_proba(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities of each class for Count Vectorizer (BernoulliNB)\n",
    "probabilities_bnb_countvec = np.squeeze(np.asarray(predictions_bnb_countvec.todense()))\n",
    "\n",
    "# Predict probabilities of each class for Count Vectorizer and TF-IDF Vectorizer (GaussianNB)\n",
    "probabilities_gnb_countvec = np.squeeze(np.asarray(predictions_gnb_countvec.todense()))\n",
    "probabilities_gnb_tfidf = np.squeeze(np.asarray(predictions_gnb_tfidf.todense()))\n",
    "\n",
    "\n",
    "# Predict probabilities of each class for TF-IDF Vectorizer (LogisticRegression+l1)\n",
    "probabilities_lr1_tfidf = np.squeeze(np.asarray(predictions_lr1_tfidf.todense()))\n",
    "\n",
    "# Predict probabilities of each class for TF-IDF Vectorizer (LogisticRegression+l2)\n",
    "probabilities_lr2_tfidf = np.squeeze(np.asarray(predictions_lr2_tfidf.todense()))\n",
    "\n",
    "# # Predict probabilities of each class for TF-IDF Vectorizer (SVC(linear kernel))\n",
    "# probabilities_svc_tfidf = np.squeeze(np.asarray(predictions_svc_tfidf.todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC-AUC values of each class for Count Vectorizer (BernoulliNB)\n",
    "auc_bnb_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_bnb_countvec[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_bnb_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for BernoulliNB with Count Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for Count Vectorizer (GaussianNB)\n",
    "auc_gnb_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_gnb_countvec[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_gnb_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for GaussianNB with Count Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (GaussianNB)\n",
    "auc_gnb_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_gnb_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_gnb_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for GaussianNB with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (LogisticRegression+l1)\n",
    "auc_lr1_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_lr1_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_lr1_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for LogisticRegression+l1 with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (LogisticRegression+l2)\n",
    "auc_lr2_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_lr2_tfidf[:,i])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_lr2_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for LogisticRegression+l2 with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for Count Vectorizer (RandomForestClassifier)\n",
    "auc_rf_countvec = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_rf_countvec[i][:,1])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_rf_countvec.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for Random Forest with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# Compute ROC-AUC values of each class for TfIdf Vectorizer (RandomForestClassifier)\n",
    "auc_rf_tfidf = []\n",
    "plt.figure(figsize=(10,8))\n",
    "for i, col in enumerate(target_cols):\n",
    "    fpr, tpr, threshold = roc_curve(y_test[col], probabilities_rf_tfidf[i][:,1])\n",
    "    auc_value = auc(fpr, tpr)\n",
    "    auc_rf_tfidf.append(auc_value)\n",
    "    plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC Curve for Random Forest with TfIdf Vectorizer')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for Count Vectorizer (XGBClassifier)\n",
    "# auc_xgb_countvec = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_xgb_countvec[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_xgb_countvec.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for XGBoost with Count Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for TfIdf Vectorizer (XGBClassifier)\n",
    "# auc_xgb_tfidf = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_xgb_tfidf[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_xgb_tfidf.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for XGBoost with TfIdf Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()\n",
    "\n",
    "# # Compute ROC-AUC values of each class for TfIdf Vectorizer (SVC(linear kernel))\n",
    "# auc_svc_tfidf = []\n",
    "# plt.figure(figsize=(10,8))\n",
    "# for i, col in enumerate(target_cols):\n",
    "#     fpr, tpr, threshold = roc_curve(y_test[col], probabilities_svc_tfidf[:,i])\n",
    "#     auc_value = auc(fpr, tpr)\n",
    "#     auc_svc_tfidf.append(auc_value)\n",
    "#     plt.plot(fpr, tpr, label='{}: {:0.5f}'.format('auc_'+col, auc_value))\n",
    "# plt.xlabel('fpr')\n",
    "# plt.ylabel('tpr')\n",
    "# plt.title('ROC Curve for LogisticRegression with TfIdf Vectorizer')\n",
    "# plt.xlim([0, 1])\n",
    "# plt.ylim([0, 1])\n",
    "# plt.legend(bbox_to_anchor=(1.01, 1), loc=2, borderaxespad=0.)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get mean column-wise ROC-AUC values\n",
    "print('ROC-AUC for BernoulliNB with Count Vectorizer = {:.4f}'.format(np.mean(auc_bnb_countvec)))\n",
    "print('ROC-AUC for GaussianNB with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_gnb_tfidf)))\n",
    "print('ROC-AUC for GaussianNB with Count Vectorizer = {:.4f}'.format(np.mean(auc_gnb_countvec)))\n",
    "print('ROC-AUC for RandomForest with Count Vectorizer = {:.4f}'.format(np.mean(auc_rf_countvec)))\n",
    "print('ROC-AUC for RandomForest with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_rf_tfidf)))\n",
    "print('ROC-AUC for LogisticRegression+l1 with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_lr1_tfidf)))\n",
    "print('ROC-AUC for LogisticRegression+l2 with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_lr2_tfidf)))\n",
    "# print('ROC-AUC for XGBoost with Count Vectorizer = {:.4f}'.format(np.mean(auc_xgb_countvec)))\n",
    "# print('ROC-AUC for XGBoost with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_xgb_tfidf)))\n",
    "# print('ROC-AUC for SVC with TfIdf Vectorizer = {:.4f}'.format(np.mean(auc_svc_tfidf)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aucs = pd.DataFrame()\n",
    "aucs['bnb_countvec'] = auc_bnb_countvec\n",
    "aucs['gnb_tfidfvec'] = auc_gnb_tfidf\n",
    "aucs['gnb_countvec'] = auc_gnb_countvec\n",
    "aucs['rf_countvec'] = auc_rf_countvec\n",
    "aucs['rf_tfidfvec'] = auc_rf_tfidf\n",
    "aucs['lr1_tfidfvec'] = auc_lr1_tfidf\n",
    "aucs['lr2_tfidfvec'] = auc_lr2_tfidf\n",
    "# aucs['xgb_countvec'] = auc_xgb_countvec\n",
    "# aucs['xgb_tfidfvec'] = auc_xgb_tfidf\n",
    "# aucs['svc_tfidfvec'] = auc_svc_tfidf\n",
    "\n",
    "aucs = aucs.T\n",
    "aucs.columns = target_cols\n",
    "aucs['mean'] = np.mean(aucs[target_cols], axis=1)\n",
    "aucs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
