{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from os import path, makedirs\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print JSON objects\n",
    "def pretty_print(data_dict):\n",
    "    try:\n",
    "        print(json.dumps(data_dict, indent=4))\n",
    "    except TypeError:\n",
    "        print(data_dict)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# Create all required folder paths (recursively)\n",
    "def create_paths(path_list):\n",
    "    print('Creating all folder paths... ', end='', flush=True)\n",
    "    for folder_path in path_list:\n",
    "        if not path.exists(folder_path):\n",
    "            makedirs(folder_path)\n",
    "    print('Done.')\n",
    "\n",
    "# Dump data to disk if not present\n",
    "def dump_data(data, name, file_path, force=False):\n",
    "    if force or not path.isfile(file_path):\n",
    "        print('Dumping {}... '.format(name), end='', flush=True)\n",
    "        pickle.dump(data, open(file_path, 'wb'))\n",
    "        print('Done.')\n",
    "    else:\n",
    "        print('Did not dump {}: File already exists in \"{}\".'.format(name, file_path))\n",
    "\n",
    "# Load all data sets\n",
    "def load_data(data_cols, data_path='../data/', clean='_clean', os=''):\n",
    "    print('Loading data... ', end='', flush=True)\n",
    "    data_sets = {}\n",
    "    \n",
    "    for col in data_cols:\n",
    "        data_sets[col] = pickle.load(open(data_path+'{}.pkl'.format(col),'rb'))\n",
    "\n",
    "    print('Done.')\n",
    "    return data_sets\n",
    "\n",
    "# Get AUC-ROC valuess for all models and target columns\n",
    "def get_auc_values(y_test, probabilities, model_list, target_cols, \\\n",
    "                          vec='countvec', features='_features'):\n",
    "    aucs = {}\n",
    "    for model in model_list:\n",
    "        print('\\tObtaining auc value for {}...'.format(model))\n",
    "        aucs[model] = {}\n",
    "        for target in target_cols:\n",
    "            fpr, tpr, threshold = roc_curve(y_test[target], probabilities[model][target])\n",
    "            auc_value = auc(fpr, tpr)\n",
    "            aucs[model][target] = auc_value\n",
    "        print('\\tDone.')\n",
    "    return aucs\n",
    "\n",
    "# Generate mean column-wise AUC for all models\n",
    "def get_mean_auc(aucs, model_list=None, target_cols=None, plot_type='model'):\n",
    "    print('\\tComputing mean AUCs... ', end='', flush=True)\n",
    "    mean_aucs = {}\n",
    "    # Compute mean auc by model\n",
    "    columns = model_list if plot_type == 'model' else target_cols\n",
    "    for col in columns:\n",
    "        mean_aucs[col] = np.mean(list(aucs[col].values()))\n",
    "    print('Done.')\n",
    "    return mean_aucs\n",
    "\n",
    "# Generate a summary AUCs dataframe for all models vs. all target columns\n",
    "def get_aucs_df(aucs, model_list, target_cols, plot_type='model'):\n",
    "    print('\\tGenerating AUCs DataFrame... ', end='', flush=True)\n",
    "    aucs_df = pd.DataFrame.from_dict(aucs)\n",
    "    aucs_df['mean'] = np.mean(aucs_df, axis=1)\n",
    "    aucs_df.loc['mean'] = np.mean(aucs_df, axis=0)\n",
    "    print('Done.')\n",
    "    return aucs_df\n",
    "\n",
    "# Plot all ROC curves, dump all mean column-wise AUCs, generate summary AUCs dataframe, and return final predictions\n",
    "def plot_and_dump_results(data_sets, best_refitted_models, model_list, vec, target_cols, plot_type='model', clean='_clean', \\\n",
    "                          os='', features='_features', plots_path='../plots/', pickle_path='../pickle_objects/', force=False):\n",
    "\n",
    "    pretty_print(aucs)\n",
    "\n",
    "    mean_aucs = get_mean_auc(aucs, model_list, target_cols, plot_type)\n",
    "\n",
    "    pretty_print(mean_aucs)\n",
    "\n",
    "    aucs_df = get_aucs_df(aucs, model_list, target_cols, plot_type)\n",
    "    \n",
    "    print('\\tAUCs DataFrame for {}:'.format(vec))\n",
    "    print(aucs_df)\n",
    "\n",
    "    print('\\t', end='', flush=True)\n",
    "    dump_data(aucs_df, 'AUCs DataFrame', '{}aucs_{}{}.pkl'.format(pickle_path, vec, features), force)\n",
    "\n",
    "    if plot_type == 'model':\n",
    "        return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all folder paths... Done.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "random.seed(1337)\n",
    "\n",
    "# Specify whether to use cleaned data or not\n",
    "is_clean, is_os = 1, 0\n",
    "clean = '_clean' if is_clean else ''\n",
    "os = '_os' if is_os else ''\n",
    "\n",
    "# Specify whether to use additional features\n",
    "use_features = 0\n",
    "features = '_features' if use_features else ''\n",
    "\n",
    "# Set all folder paths\n",
    "data_path = '../data/'\n",
    "pickle_path = '../pickle_objects/'\n",
    "model_path = pickle_path + 'models{}/'.format(features)\n",
    "plots_path = '../plots{}/'.format(features)\n",
    "\n",
    "# Specify initial variables\n",
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "vectorizers = ['countvec', 'tfidf']\n",
    "plot_types = ['model', 'target']\n",
    "data_cols = ['data', 'X_train', 'X_val', 'X_train_val', 'X_test', 'y_train', 'y_val', 'y_train_val', 'y_test']\n",
    "for i, col in enumerate(data_cols):\n",
    "    data_cols[i] = col + clean + os\n",
    "\n",
    "create_paths([data_path, pickle_path, plots_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... Done.\n"
     ]
    }
   ],
   "source": [
    "# Load all data sets\n",
    "data_sets = load_data(data_cols, data_path, clean=clean, os=os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models to be run\n",
    "model_list = ['bnb', 'lrl1', 'lrl2', 'nbsvm', 'rf', 'xgb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pickle.load(open('../pickle_objects/probabilities{}.pkl'.format(features), 'rb'))\n",
    "predictions = pickle.load(open('../pickle_objects/predictions{}.pkl'.format(features), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_xgb_rf'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_xgb_rf'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_rf'][target] = \\\n",
    "            0.5*(probabilities[vec]['xgb'][target] + probabilities[vec]['rf'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_xgb_lrl1'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_xgb_lrl1'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_lrl1'][target] = \\\n",
    "            0.5*(probabilities[vec]['xgb'][target] + probabilities[vec]['lrl1'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_xgb_lrl2'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_xgb_lrl2'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_lrl2'][target] = \\\n",
    "            0.5*(probabilities[vec]['xgb'][target] + probabilities[vec]['lrl2'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_lrl1_rf'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_lrl1_rf'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_rf'][target] = \\\n",
    "            0.5*(probabilities[vec]['lrl1'][target] + probabilities[vec]['rf'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_lrl2_rf'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_lrl2_rf'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_lrl2_rf'][target] = \\\n",
    "            0.5*(probabilities[vec]['lrl2'][target] + probabilities[vec]['rf'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_lrl1_lrl2'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_lrl1_lrl2'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_lrl1_lrl2'][target] = \\\n",
    "            0.5*(probabilities[vec]['lrl1'][target] + probabilities[vec]['lrl2'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_not_bnb'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_not_bnb'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_not_bnb'][target] = \\\n",
    "            0.2*(probabilities[vec]['lrl1'][target] + probabilities[vec]['lrl2'][target] + \\\n",
    "                probabilities[vec]['rf'][target] + probabilities[vec]['xgb'][target] + \\\n",
    "                probabilities[vec]['nbsvm'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_tree_linear'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_tree_linear'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_tree_linear'][target] = \\\n",
    "            0.25*(probabilities[vec]['lrl1'][target] + probabilities[vec]['lrl2'][target] + \\\n",
    "                probabilities[vec]['rf'][target] + probabilities[vec]['xgb'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_xgb_nbsvm_lrl2'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_xgb_nbsvm_lrl2'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_nbsvm_lrl2'][target] = \\\n",
    "            (1./3.)*(probabilities[vec]['nbsvm'][target] + probabilities[vec]['lrl2'][target] + \\\n",
    "                probabilities[vec]['xgb'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_xgb_nbsvm'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_xgb_nbsvm'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_xgb_nbsvm'][target] = \\\n",
    "            0.5*(probabilities[vec]['nbsvm'][target] + probabilities[vec]['xgb'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_lrl2_nbsvm'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_lrl2_nbsvm'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_lrl2_nbsvm'][target] = \\\n",
    "            0.5*(probabilities[vec]['lrl2'][target] + probabilities[vec]['nbsvm'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vec in vectorizers:\n",
    "    probabilities[vec]['ensemble_linear_nbsvm'] = {}\n",
    "    for target in target_cols:\n",
    "        probabilities[vec]['ensemble_linear_nbsvm'][target] = [0.]*len(data_sets['y_test_clean'])\n",
    "        for model in model_list:\n",
    "            probabilities[vec]['ensemble_linear_nbsvm'][target] = \\\n",
    "            (1./3.)*(probabilities[vec]['lrl2'][target] + probabilities[vec]['nbsvm'][target] + \\\n",
    "                probabilities[vec]['lrl1'][target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tObtaining auc value for ensemble_xgb_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_lrl1...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl1_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl2_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl1_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_not_bnb...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_tree_linear...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_nbsvm_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_nbsvm...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_linear_nbsvm...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl2_nbsvm...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_lrl1...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl1_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl2_rf...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl1_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_not_bnb...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_tree_linear...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_nbsvm_lrl2...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_xgb_nbsvm...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_linear_nbsvm...\n",
      "\tDone.\n",
      "\tObtaining auc value for ensemble_lrl2_nbsvm...\n",
      "\tDone.\n"
     ]
    }
   ],
   "source": [
    "aucs = {}\n",
    "for vec in vectorizers:\n",
    "    aucs[vec] = get_auc_values(data_sets['y_test_clean'], probabilities[vec], \\\n",
    "                               ['ensemble_xgb_rf', 'ensemble_xgb_lrl1', 'ensemble_xgb_lrl2', \\\n",
    "                               'ensemble_lrl1_rf', 'ensemble_lrl2_rf', 'ensemble_lrl1_lrl2', \\\n",
    "                               'ensemble_not_bnb', 'ensemble_tree_linear', 'ensemble_xgb_nbsvm_lrl2', \\\n",
    "                               'ensemble_xgb_nbsvm', 'ensemble_linear_nbsvm', 'ensemble_lrl2_nbsvm'], \\\n",
    "                               target_cols, vec, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>insult</th>\n",
       "      <th>obscene</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>threat</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ensemble_linear_nbsvm</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_lrl1_lrl2</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_lrl1_rf</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_lrl2_nbsvm</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.968</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_lrl2_rf</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_not_bnb</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_tree_linear</th>\n",
       "      <td>0.952</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_xgb_lrl1</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_xgb_lrl2</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_xgb_nbsvm</th>\n",
       "      <td>0.951</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_xgb_nbsvm_lrl2</th>\n",
       "      <td>0.953</td>\n",
       "      <td>0.955</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ensemble_xgb_rf</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         identity_hate  insult  obscene  severe_toxic  threat  \\\n",
       "ensemble_linear_nbsvm            0.950   0.953    0.968         0.977   0.975   \n",
       "ensemble_lrl1_lrl2               0.950   0.953    0.969         0.977   0.974   \n",
       "ensemble_lrl1_rf                 0.500   0.500    0.500         0.500   0.500   \n",
       "ensemble_lrl2_nbsvm              0.951   0.953    0.968         0.977   0.977   \n",
       "ensemble_lrl2_rf                 0.952   0.956    0.970         0.974   0.973   \n",
       "ensemble_not_bnb                 0.952   0.956    0.970         0.976   0.975   \n",
       "ensemble_tree_linear             0.952   0.956    0.970         0.975   0.974   \n",
       "ensemble_xgb_lrl1                0.949   0.954    0.970         0.976   0.971   \n",
       "ensemble_xgb_lrl2                0.953   0.955    0.971         0.976   0.975   \n",
       "ensemble_xgb_nbsvm               0.951   0.954    0.970         0.976   0.976   \n",
       "ensemble_xgb_nbsvm_lrl2          0.953   0.955    0.971         0.977   0.978   \n",
       "ensemble_xgb_rf                  0.947   0.954    0.969         0.974   0.967   \n",
       "\n",
       "                         toxic  \n",
       "ensemble_linear_nbsvm    0.935  \n",
       "ensemble_lrl1_lrl2       0.934  \n",
       "ensemble_lrl1_rf         0.500  \n",
       "ensemble_lrl2_nbsvm      0.935  \n",
       "ensemble_lrl2_rf         0.934  \n",
       "ensemble_not_bnb         0.935  \n",
       "ensemble_tree_linear     0.935  \n",
       "ensemble_xgb_lrl1        0.934  \n",
       "ensemble_xgb_lrl2        0.934  \n",
       "ensemble_xgb_nbsvm       0.934  \n",
       "ensemble_xgb_nbsvm_lrl2  0.935  \n",
       "ensemble_xgb_rf          0.934  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = pd.DataFrame.from_dict(aucs['tfidf'])\n",
    "np.round(t.T, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ensemble_linear_nbsvm      0.959580\n",
       "ensemble_lrl1_lrl2         0.959497\n",
       "ensemble_lrl1_rf           0.500000\n",
       "ensemble_lrl2_nbsvm        0.960037\n",
       "ensemble_lrl2_rf           0.959589\n",
       "ensemble_not_bnb           0.960798\n",
       "ensemble_tree_linear       0.960431\n",
       "ensemble_xgb_lrl1          0.959103\n",
       "ensemble_xgb_lrl2          0.960679\n",
       "ensemble_xgb_nbsvm         0.960113\n",
       "ensemble_xgb_nbsvm_lrl2    0.961454\n",
       "ensemble_xgb_rf            0.957275\n",
       "dtype: float64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31915.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.010039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.008026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.007567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.009967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.150447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  31915.000000\n",
       "mean       0.010039\n",
       "std        0.008026\n",
       "min        0.001010\n",
       "25%        0.007567\n",
       "50%        0.008930\n",
       "75%        0.009967\n",
       "max        0.150447"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(probabilities['tfidf']['rf']['severe_toxic']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(predictions['tfidf']['rf']['severe_toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data_clean', 'X_train_clean', 'X_val_clean', 'X_train_val_clean', 'X_test_clean', 'y_train_clean', 'y_val_clean', 'y_train_val_clean', 'y_test_clean'])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets['X_train_val_clean_tfidf_features'] = pickle.load(open('../data/X_train_val_clean_tfidf_features.pkl', 'rb'))\n",
    "data_sets['y_train_val_clean'] = pickle.load(open('../data/X_train_val_clean.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(data_sets['X_train_val_clean_tfidf_features'], data_sets['y_train_val_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
