{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import pickle\n",
    "from os import path, makedirs\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import clone\n",
    "from scipy import sparse\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from nbsvm import NBSVMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretty print JSON objects\n",
    "def pretty_print(data_dict):\n",
    "    try:\n",
    "        print(json.dumps(data_dict, indent=4))\n",
    "    except TypeError:\n",
    "        print(data_dict)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "\n",
    "# Create all required folder paths (recursively)\n",
    "def create_paths(path_list):\n",
    "    print('Creating all folder paths... ', end='', flush=True)\n",
    "    for folder_path in path_list:\n",
    "        if not path.exists(folder_path):\n",
    "            makedirs(folder_path)\n",
    "    print('Done.')\n",
    "\n",
    "# Dump data to disk if not present\n",
    "def dump_data(data, name, file_path, force=False):\n",
    "    if force or not path.isfile(file_path):\n",
    "        print('Dumping {}... '.format(name), end='', flush=True)\n",
    "        pickle.dump(data, open(file_path, 'wb'))\n",
    "        print('Done.')\n",
    "    else:\n",
    "        print('Did not dump {}: File already exists in \"{}\".'.format(name, file_path))\n",
    "\n",
    "# Load all data sets\n",
    "def load_data(data_cols, data_path='../data/', clean='_clean', os=''):\n",
    "    print('Loading data... ', end='', flush=True)\n",
    "    data_sets = {}\n",
    "    \n",
    "    for col in data_cols:\n",
    "        data_sets[col] = pickle.load(open(data_path+'{}.pkl'.format(col),'rb'))\n",
    "\n",
    "    print('Done.')\n",
    "    return data_sets\n",
    "\n",
    "# Load all ngrams data if present, otherwise fit on data and dump them\n",
    "def load_ngrams(data_sets, data_col, num_feats, ngrams, vectorizers, pickle_path='../pickle_objects/', clean='_clean', os=''):\n",
    "    data_col += clean+os\n",
    "    ngrams_data = {}\n",
    "    ngram_range = list(map(lambda x: x+1,range(ngrams)))\n",
    "    vec_params = {'analyzer': 'word', 'lowercase': True,'max_features': num_feats, 'ngram_range': ngram_range}\n",
    "    \n",
    "    for vec in vectorizers:\n",
    "        # Load vectorizer if present\n",
    "        file_name = '{}{}_ngrams_{}_{}_{}.pkl'.format(pickle_path, vec, data_col, num_feats, ngrams)\n",
    "        if path.isfile(file_name):\n",
    "            print('Loading {} ngrams... '.format(vec), end='', flush=True)\n",
    "            ngrams_data[vec] = pickle.load(open(file_name, 'rb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            # Fit, store, and load vectorizer\n",
    "            print('{} ngrams not found. Fitting them... '.format(vec), end='', flush=True)\n",
    "            ngrams_vec = CountVectorizer(**vec_params) if vec == 'countvec' else TfidfVectorizer(**vec_params)\n",
    "            ngrams_vec.fit(data_sets[data_col]['comment_text'])\n",
    "            ngrams_data[vec] = ngrams_vec\n",
    "            dump_data(ngrams_vec, '{} ngrams'.format(vec), file_name)\n",
    "    return ngrams_data\n",
    "\n",
    "# Transform data on fitted ngrams data\n",
    "def transform_to_ngrams(data_sets, data_cols, ngrams_data, vectorizers):\n",
    "    print('Transforming data to ngrams... ', end='', flush=True)\n",
    "    for data in data_cols:\n",
    "        for vec in vectorizers:\n",
    "            data_sets[data+'_'+vec] = ngrams_data[vec].transform(data_sets[data]['comment_text'])\n",
    "    print('Done.')\n",
    "    return data_sets\n",
    "\n",
    "# Extract features and to data\n",
    "def generate_features(data_sets, data_cols, vectorizers):\n",
    "    print('Extracting features from data...')\n",
    "\n",
    "    # Get all data sets with features\n",
    "    X_cols = [col for col in data_cols if 'X' in col]\n",
    "    \n",
    "    # Add features\n",
    "    for col in X_cols:\n",
    "        for vec in vectorizers:\n",
    "            # Comment Text Length\n",
    "            print(\"\\tGenerating 'comment_length' for {}_{}... \".format(col, vec), end='', flush=True)\n",
    "            data_sets[col+'_'+vec+features] = np.hstack((data_sets[col+'_'+vec].todense(), \\\n",
    "                                                data_sets[col]['comment_text'].str.len().values.reshape(-1,1)))\n",
    "            print('Done.')\n",
    "\n",
    "            # Standard Deviation of Word Length in Comment Text\n",
    "            print(\"\\tGenerating 'word_length_std' for {}_{}... \".format(col, vec), end='', flush=True)\n",
    "            stddevs = np.array([])\n",
    "            for row in data_sets[col]['comment_text'].str.split().iteritems():\n",
    "                value = np.std([len(word) for word in row[1]]) if len(row[1]) else 0.\n",
    "                stddevs = np.append(stddevs, value)\n",
    "            print('Done.')\n",
    "            data_sets[col+'_'+vec+features] = np.hstack((data_sets[col+'_'+vec+features], stddevs.reshape(-1,1)))\n",
    "            \n",
    "            print('Converting back to sparse matrix... ', end='', flush=True)\n",
    "            data_sets[col+'_'+vec+features] = sparse.csr_matrix(data_sets[col+'_'+vec+features])\n",
    "            print('Done.')\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "    return data_sets\n",
    "\n",
    "# Dump all models of a type fitted on all target columns\n",
    "def dump_models(model, X, model_name, target_cols, model_path='../pickle_objects/models/', force=False):\n",
    "    for target in target_cols:\n",
    "        file_name = '{}{}_{}_{}.pkl'.format(model_path, model_name, X, target)\n",
    "        if force or not path.isfile(file_name):\n",
    "            print('\\t\\tDumping {} fitted on {}... '.format(model_name, target), end='', flush=True)\n",
    "            pickle.dump(model[target], open(file_name, 'wb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('\\t\\tDid not dump {} fitted on {}: File already exists in \"{}\".' \\\n",
    "                  .format(model_name, target, file_name))\n",
    "\n",
    "# Fit a model on all target columns after performing grid search or with best parameters\n",
    "def fit_model(base_model, X, y, param_grid, target_cols, scoring='roc_auc', cv=None):\n",
    "    if cv:\n",
    "        models, mean_val_scores, params = {}, [], []\n",
    "        for target in target_cols:\n",
    "            print('\\t\\tRunning for {}... '.format(target), end='', flush=True)\n",
    "            model_target = GridSearchCV(base_model, param_grid, cv=cv, scoring=scoring, n_jobs=4, refit=False)\n",
    "            model_target.fit(X, y[target])\n",
    "            print('Done.')\n",
    "            mean_val_scores.append(model_target.cv_results_['mean_test_score'])\n",
    "            if not params:\n",
    "                params = model_target.cv_results_['params']\n",
    "        mean_val_scores = np.mean(np.array(mean_val_scores), axis=0)\n",
    "        best_param_idx = np.argmax(mean_val_scores)\n",
    "        models['best_params_'], models['best_mean_score_'] = \\\n",
    "        params[best_param_idx], mean_val_scores[best_param_idx]\n",
    "    else:\n",
    "        models = {}\n",
    "        for target in target_cols:\n",
    "            model = clone(base_model)\n",
    "            print('\\t\\tRunning for {}... '.format(target), end='', flush=True)\n",
    "            model.set_params(**param_grid).fit(X, y[target])\n",
    "            models[target] = model\n",
    "            print('Done.')\n",
    "    return models\n",
    "\n",
    "# Fit all models on all target columns or dump the refitted ones with best parameters\n",
    "def fit_all_models(data_sets, data_cols, model_list, param_grids, target_cols, \\\n",
    "                   model_path='../pickle_path/models/', cv=None):\n",
    "    best_models, best_params, best_scores = {}, {}, {}\n",
    "    X, y = data_cols\n",
    "    for model in model_list:\n",
    "        print('\\tRunning {}...'.format(model))\n",
    "        best_models[model] = fit_model(model_list[model], data_sets[X], data_sets[y], \\\n",
    "                                       param_grids[model], target_cols, 'roc_auc', cv)\n",
    "        print('\\tDone.')\n",
    "        if cv:\n",
    "            pretty_print(best_models[model])\n",
    "        else:\n",
    "            print('\\tDumping {}... '.format(model))\n",
    "            dump_models(best_models[model], X, model, target_cols, model_path)\n",
    "            print('\\tDone.')\n",
    "    return best_models\n",
    "\n",
    "# Refit all models on all target columns with best parameters\n",
    "def refit_best_models(data_sets, model_list, data_cols, best_models, \\\n",
    "                      target_cols, model_path='../pickle_path/models/'):\n",
    "    # Refit all models with all data sets with best hyperparameters\n",
    "    print('Refitting with best parameters...')\n",
    "    best_params = {}\n",
    "    for model in model_list:\n",
    "        best_params[model] = best_models[model]['best_params_']\n",
    "    best_refitted_models = fit_all_models(data_sets, data_cols, model_list, best_params, \\\n",
    "                                          target_cols, model_path, cv=None)\n",
    "    print('Done.')\n",
    "    return best_refitted_models\n",
    "\n",
    "# Load all models of a type fitted on all target columns\n",
    "def load_models(model_name, X, target_cols, model_path='../pickle_objects/models/'):\n",
    "    model = {}\n",
    "    for target in target_cols:\n",
    "        file_name = '{}{}_{}_{}.pkl'.format(model_path, model_name, X, target)\n",
    "        if path.isfile(file_name):\n",
    "            print('\\tLoading {} fitted on {}... '.format(model_name, target), end='', flush=True)\n",
    "            model[target] = pickle.load(open(file_name, 'rb'))\n",
    "            print('Done.')\n",
    "        else:\n",
    "            print('\\tDid not load {} fitted on {}: File not found in \"{}\".' \\\n",
    "                  .format(model_name, target, file_name))\n",
    "    return model\n",
    "\n",
    "# Load all models fitted on all target columns\n",
    "def load_all_models(model_list, data_cols, target_cols, model_path='../pickle_path/models/'):\n",
    "    print('Loading models fitted with best parameters...')\n",
    "    best_models = {}\n",
    "    X, y = data_cols\n",
    "    for model_name in model_list:\n",
    "        best_models[model_name] = load_models(model_name, X, target_cols, model_path)\n",
    "    print('Done.')\n",
    "    return best_models\n",
    "\n",
    "# Predict labels and probabilities for all models for all target columns\n",
    "def predict_labels_and_probas(fitted_models, model_list, X, target_cols):\n",
    "    probabilities, predictions = {}, {}\n",
    "    for model in model_list:\n",
    "        print('\\tPredicting labels and probabilities for {}...'.format(model))\n",
    "        probabilities[model], predictions[model] = {}, {}\n",
    "        for target in target_cols:\n",
    "            print('\\t\\tPredicting for {}... '.format(target), end='', flush=True)\n",
    "            probabilities[model][target] = fitted_models[model][target].predict_proba(X)[:,1]\n",
    "            predictions[model][target] = fitted_models[model][target].predict(X)\n",
    "            print('Done.')\n",
    "        print('\\tDone.')\n",
    "    return probabilities, predictions\n",
    "\n",
    "# Plot ROC curves for all models / target columns\n",
    "def plot_model_roc_curves(y_test, probabilities, model_list, target_cols, vec='countvec', \\\n",
    "                          plot_type='model', features='_features', plots_path='../plots/', force=False):\n",
    "    aucs = {}\n",
    "    # Plot by model\n",
    "    if plot_type == 'model':\n",
    "        for model in model_list:\n",
    "            print('\\tPlotting ROC curve for {}...'.format(model))\n",
    "            aucs[model] = {}\n",
    "            plt.figure(figsize=(5,4))\n",
    "            for target in target_cols:\n",
    "                fpr, tpr, threshold = roc_curve(y_test[target], probabilities[model][target])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                aucs[model][target] = auc_value\n",
    "                plt.plot(fpr, tpr, label='{}: {:0.3f}'.format('auc{}_'.format(features)+target, auc_value))\n",
    "            plt.xlabel('fpr')\n",
    "            plt.ylabel('tpr')\n",
    "            plt.title('ROC Curve for {}{} with {}'.format(model, features, vec))\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend(loc=4)\n",
    "            file_path = plots_path+'roc_'+model+'_'+vec+features+'.jpg'\n",
    "            if force or not path.isfile(file_path):\n",
    "                print('\\tDumping ROC plot to {}... '.format(file_path), end='', flush=True)\n",
    "                plt.savefig(file_path)\n",
    "                print('Done.')\n",
    "            else:\n",
    "                print('\\tDid not dump ROC plot: File already exists in \"{}\".'.format(file_path))\n",
    "            plt.close('all')\n",
    "            print('\\tDone.')\n",
    "    # Plot by target column\n",
    "    elif plot_type == 'target':\n",
    "        for target in target_cols:\n",
    "            print('\\tPlotting ROC curve for {}...'.format(target))\n",
    "            aucs[target] = {}\n",
    "            plt.figure(figsize=(5,4))\n",
    "            for model in model_list:\n",
    "                fpr, tpr, threshold = roc_curve(y_test[target], probabilities[model][target])\n",
    "                auc_value = auc(fpr, tpr)\n",
    "                aucs[target][model] = auc_value\n",
    "                plt.plot(fpr, tpr, label='{}: {:0.3f}'.format('auc{}_'.format(features)+model, auc_value))\n",
    "            plt.xlabel('fpr')\n",
    "            plt.ylabel('tpr')\n",
    "            plt.title('ROC Curve for {}{} with {}'.format(target, features, vec))\n",
    "            plt.xlim([0, 1])\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend(loc=4)\n",
    "            file_path = plots_path+'roc_'+target+'_'+vec+features+'.jpg'\n",
    "            if force or not path.isfile(file_path):\n",
    "                print('\\tDumping ROC plot to {}... '.format(file_path), end='', flush=True)\n",
    "                plt.savefig(file_path)\n",
    "                print('\\tDone.')\n",
    "            else:\n",
    "                print('\\tDid not dump ROC plot: File already exists in \"{}\".'.format(file_path))\n",
    "            plt.close('all')\n",
    "            print('\\tDone.')\n",
    "    else:\n",
    "        raise ValueError(\"Parameter 'plot_type' must be one of 'model' or 'target'.\")\n",
    "    return aucs\n",
    "\n",
    "# Generate mean column-wise AUC for all models\n",
    "def get_mean_auc(aucs, model_list=None, target_cols=None, plot_type='model'):\n",
    "    print('\\tComputing mean AUCs... ', end='', flush=True)\n",
    "    mean_aucs = {}\n",
    "    # Compute mean auc by model\n",
    "    columns = model_list if plot_type == 'model' else target_cols\n",
    "    for col in columns:\n",
    "        mean_aucs[col] = np.mean(list(aucs[col].values()))\n",
    "    print('Done.')\n",
    "    return mean_aucs\n",
    "\n",
    "# Generate a summary AUCs dataframe for all models vs. all target columns\n",
    "def get_aucs_df(aucs, model_list, target_cols, plot_type='model'):\n",
    "    print('\\tGenerating AUCs DataFrame... ', end='', flush=True)\n",
    "    aucs_df = pd.DataFrame.from_dict(aucs)\n",
    "    aucs_df['mean'] = np.mean(aucs_df, axis=1)\n",
    "    aucs_df.loc['mean'] = np.mean(aucs_df, axis=0)\n",
    "    print('Done.')\n",
    "    return aucs_df\n",
    "\n",
    "# Plot all ROC curves, dump all mean column-wise AUCs, generate summary AUCs dataframe, and return final predictions\n",
    "def plot_and_dump_results(data_sets, best_refitted_models, model_list, vec, target_cols, plot_type='model', clean='_clean', \\\n",
    "                          os='', features='_features', plots_path='../plots/', pickle_path='../pickle_objects/', force=False):\n",
    "\n",
    "    probabilities, predictions = predict_labels_and_probas(best_refitted_models[vec], model_list, \\\n",
    "                                                           data_sets['X_test'+clean+os+'_'+vec+features], target_cols)\n",
    "    \n",
    "    aucs = plot_model_roc_curves(data_sets['y_test'+clean+os], probabilities, model_list, \\\n",
    "                                 target_cols, vec, plot_type, features, plots_path, force)\n",
    "\n",
    "    pretty_print(aucs)\n",
    "\n",
    "    mean_aucs = get_mean_auc(aucs, model_list, target_cols, plot_type)\n",
    "\n",
    "    pretty_print(mean_aucs)\n",
    "\n",
    "    aucs_df = get_aucs_df(aucs, model_list, target_cols, plot_type)\n",
    "    \n",
    "    print('\\tAUCs DataFrame for {}:'.format(vec))\n",
    "    print(aucs_df)\n",
    "\n",
    "    print('\\t', end='', flush=True)\n",
    "    dump_data(aucs_df, 'AUCs DataFrame', '{}aucs_{}{}.pkl'.format(pickle_path, vec, features), force)\n",
    "\n",
    "    if plot_type == 'model':\n",
    "        return probabilities, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all folder paths... Done.\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "random.seed(1337)\n",
    "\n",
    "# Specify whether to use cleaned data or not\n",
    "is_clean, is_os = 1, 0\n",
    "clean = '_clean' if is_clean else ''\n",
    "os = '_os' if is_os else ''\n",
    "\n",
    "# Specify whether to use additional features\n",
    "use_features = 1\n",
    "features = '_features' if use_features else ''\n",
    "\n",
    "# Set all folder paths\n",
    "data_path = '../data/'\n",
    "pickle_path = '../pickle_objects/'\n",
    "model_path = pickle_path + 'models{}/'.format(features)\n",
    "plots_path = '../plots{}/'.format(features)\n",
    "\n",
    "# Specify initial variables\n",
    "target_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "vectorizers = ['countvec', 'tfidf']\n",
    "plot_types = ['model', 'target']\n",
    "data_cols = ['data', 'X_train', 'X_val', 'X_train_val', 'X_test', 'y_train', 'y_val', 'y_train_val', 'y_test']\n",
    "for i, col in enumerate(data_cols):\n",
    "    data_cols[i] = col + clean + os\n",
    "\n",
    "create_paths([data_path, pickle_path, plots_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data... Done.\n"
     ]
    }
   ],
   "source": [
    "# Load all data sets\n",
    "data_sets = load_data(data_cols, data_path, clean=clean, os=os)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets['data_clean']['comment_length'] = data_sets['data_clean']['comment_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comment_length</th>\n",
       "      <td>159571</td>\n",
       "      <td>227</td>\n",
       "      <td>361</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>116</td>\n",
       "      <td>245</td>\n",
       "      <td>6471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count  mean  std  min  25%  50%  75%   max\n",
       "comment_length  159571   227  361    0   54  116  245  6471"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['data_clean'][['comment_length']].describe().astype(int).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all models to be run\n",
    "model_list = {\n",
    "    'bnb': BernoulliNB(),\n",
    "    'lrl1': LogisticRegression(penalty='l1'),\n",
    "    'lrl2': LogisticRegression(penalty='l2'),\n",
    "    'nbsvm': NBSVMClassifier(dual=True),\n",
    "    'rf': RandomForestClassifier(),\n",
    "    'xgb': XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Refit all models with best parameters on ngrams fitted on X_train_val (+clean+os)\n",
    "# best_refitted_models = {}\n",
    "# for vec in vectorizers:\n",
    "#     print('\\nRunning for {}...'.format(vec))\n",
    "#     data_cols = ('X_train_val'+clean+os+'_'+vec+features, 'y_train_val'+clean+os)\n",
    "#     # Load models if already fitted and dumped\n",
    "#     best_refitted_models[vec] = load_all_models(model_list, data_cols, target_cols, model_path)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target in target_cols:\n",
    "#     importances = best_refitted_models['tfidf']['xgb'][target].feature_importances_\n",
    "#     indices = np.argsort(importances)[::-1]\n",
    "#     print('comment_length', importances[-2], )\n",
    "#     print('stddev(word_length)', importances[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = ['comment_length', 'word_length_std']\n",
    "# labels.extend(['']*len(indices[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importances = best_refitted_models['tfidf']['xgb']['toxic'].feature_importances_\n",
    "# indices = np.argsort(importances)[::-1]\n",
    "# # Plot the feature importances of the tree\n",
    "# plt.figure(figsize=(7,4))\n",
    "# plt.bar(range(len(indices)), importances[indices], color=\"r\", align=\"center\")\n",
    "# plt.title(\"XGBoost Feature Importance Bar Plot for 'toxic' with TfIdfVectorizer\")\n",
    "# plt.xlabel('Feature Name')\n",
    "# plt.ylabel('Feature Importance')\n",
    "# plt.xticks(range(len(indices)), labels, rotation=35, horizontalalignment='right')\n",
    "# plt.xlim([-1, 20])\n",
    "# plt.tight_layout()\n",
    "# plt.savefig('feature_importance.jpg')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = pickle.load(open('../pickle_objects/probabilities{}.pkl'.format(features), 'rb'))\n",
    "predictions = pickle.load(open('../pickle_objects/predictions{}.pkl'.format(features), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sets['X_test_clean']['comment_length'] = data_sets['X_test_clean']['comment_text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>74e4b95b9cb9834a</td>\n",
       "      <td>attack 98 .. begin not stop sock puppet proxy ...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148898</th>\n",
       "      <td>53cb4186efea9ee2</td>\n",
       "      <td>wild goose remove phrase derive ancient irish ...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89968</th>\n",
       "      <td>f0b3496b164a5c17</td>\n",
       "      <td>summary agree wikipedia article picture prefer...</td>\n",
       "      <td>868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143624</th>\n",
       "      <td>004a6e2dde1f82eb</td>\n",
       "      <td>-pron- like opportunity remind -pron- no long ...</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>59db79e849a4cfd8</td>\n",
       "      <td>hey right thing shorten european commission lo...</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "43797   74e4b95b9cb9834a  attack 98 .. begin not stop sock puppet proxy ...   \n",
       "148898  53cb4186efea9ee2  wild goose remove phrase derive ancient irish ...   \n",
       "89968   f0b3496b164a5c17  summary agree wikipedia article picture prefer...   \n",
       "143624  004a6e2dde1f82eb  -pron- like opportunity remind -pron- no long ...   \n",
       "33692   59db79e849a4cfd8  hey right thing shorten european commission lo...   \n",
       "\n",
       "        comment_length  \n",
       "43797              155  \n",
       "148898             199  \n",
       "89968              868  \n",
       "143624             293  \n",
       "33692              171  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['X_test_clean'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aucs_countvec = pickle.load(open('../pickle_objects/aucs_countvec.pkl', 'rb'))\n",
    "# aucs_countvec_features = pickle.load(open('../pickle_objects/aucs_countvec_features.pkl', 'rb'))\n",
    "# aucs_tfidf = pickle.load(open('../pickle_objects/aucs_tfidf.pkl', 'rb'))\n",
    "# aucs_tfidf_features = pickle.load(open('../pickle_objects/aucs_tfidf_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(aucs_countvec_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(aucs_countvec, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(aucs_tfidf, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.round(aucs_tfidf_features, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>comment_length</th>\n",
       "      <td>31915.0</td>\n",
       "      <td>226.770421</td>\n",
       "      <td>359.842055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>4999.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  count        mean         std  min   25%    50%    75%  \\\n",
       "comment_length  31915.0  226.770421  359.842055  0.0  54.0  116.0  245.0   \n",
       "\n",
       "                   max  \n",
       "comment_length  4999.0  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sets['X_test_clean'].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'insult'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>insult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>74e4b95b9cb9834a</td>\n",
       "      <td>attack 98 .. begin not stop sock puppet proxy ...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148898</th>\n",
       "      <td>53cb4186efea9ee2</td>\n",
       "      <td>wild goose remove phrase derive ancient irish ...</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89968</th>\n",
       "      <td>f0b3496b164a5c17</td>\n",
       "      <td>summary agree wikipedia article picture prefer...</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143624</th>\n",
       "      <td>004a6e2dde1f82eb</td>\n",
       "      <td>-pron- like opportunity remind -pron- no long ...</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>59db79e849a4cfd8</td>\n",
       "      <td>hey right thing shorten european commission lo...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "43797   74e4b95b9cb9834a  attack 98 .. begin not stop sock puppet proxy ...   \n",
       "148898  53cb4186efea9ee2  wild goose remove phrase derive ancient irish ...   \n",
       "89968   f0b3496b164a5c17  summary agree wikipedia article picture prefer...   \n",
       "143624  004a6e2dde1f82eb  -pron- like opportunity remind -pron- no long ...   \n",
       "33692   59db79e849a4cfd8  hey right thing shorten european commission lo...   \n",
       "\n",
       "        comment_length  insult  \n",
       "43797              155       0  \n",
       "148898             199       0  \n",
       "89968              868       0  \n",
       "143624             293       0  \n",
       "33692              171       0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((data_sets['X_test_clean'], data_sets['y_test_clean'][target]), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = pd.DataFrame(probabilities['tfidf']['lrl2'][target], columns = [target+'_prob'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insult_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.022156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.014450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   insult_prob\n",
       "0     0.041605\n",
       "1     0.022156\n",
       "2     0.009205\n",
       "3     0.055766\n",
       "4     0.014450"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame(predictions['tfidf']['lrl2'][target], columns = [target+'_pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insult_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   insult_pred\n",
       "0            0\n",
       "1            0\n",
       "2            0\n",
       "3            0\n",
       "4            0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>insult</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>74e4b95b9cb9834a</td>\n",
       "      <td>attack 98 .. begin not stop sock puppet proxy ...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148898</th>\n",
       "      <td>53cb4186efea9ee2</td>\n",
       "      <td>wild goose remove phrase derive ancient irish ...</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89968</th>\n",
       "      <td>f0b3496b164a5c17</td>\n",
       "      <td>summary agree wikipedia article picture prefer...</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143624</th>\n",
       "      <td>004a6e2dde1f82eb</td>\n",
       "      <td>-pron- like opportunity remind -pron- no long ...</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>59db79e849a4cfd8</td>\n",
       "      <td>hey right thing shorten european commission lo...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "43797   74e4b95b9cb9834a  attack 98 .. begin not stop sock puppet proxy ...   \n",
       "148898  53cb4186efea9ee2  wild goose remove phrase derive ancient irish ...   \n",
       "89968   f0b3496b164a5c17  summary agree wikipedia article picture prefer...   \n",
       "143624  004a6e2dde1f82eb  -pron- like opportunity remind -pron- no long ...   \n",
       "33692   59db79e849a4cfd8  hey right thing shorten european commission lo...   \n",
       "\n",
       "        comment_length  insult  \n",
       "43797              155       0  \n",
       "148898             199       0  \n",
       "89968              868       0  \n",
       "143624             293       0  \n",
       "33692              171       0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs.index = data.index\n",
    "preds.index = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>insult</th>\n",
       "      <th>insult_prob</th>\n",
       "      <th>insult_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>74e4b95b9cb9834a</td>\n",
       "      <td>attack 98 .. begin not stop sock puppet proxy ...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148898</th>\n",
       "      <td>53cb4186efea9ee2</td>\n",
       "      <td>wild goose remove phrase derive ancient irish ...</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89968</th>\n",
       "      <td>f0b3496b164a5c17</td>\n",
       "      <td>summary agree wikipedia article picture prefer...</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143624</th>\n",
       "      <td>004a6e2dde1f82eb</td>\n",
       "      <td>-pron- like opportunity remind -pron- no long ...</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055766</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>59db79e849a4cfd8</td>\n",
       "      <td>hey right thing shorten european commission lo...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "43797   74e4b95b9cb9834a  attack 98 .. begin not stop sock puppet proxy ...   \n",
       "148898  53cb4186efea9ee2  wild goose remove phrase derive ancient irish ...   \n",
       "89968   f0b3496b164a5c17  summary agree wikipedia article picture prefer...   \n",
       "143624  004a6e2dde1f82eb  -pron- like opportunity remind -pron- no long ...   \n",
       "33692   59db79e849a4cfd8  hey right thing shorten european commission lo...   \n",
       "\n",
       "        comment_length  insult  insult_prob  insult_pred  \n",
       "43797              155       0     0.041605            0  \n",
       "148898             199       0     0.022156            0  \n",
       "89968              868       0     0.009205            0  \n",
       "143624             293       0     0.055766            0  \n",
       "33692              171       0     0.014450            0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat((data, probs, preds), axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>insult</th>\n",
       "      <th>insult_prob</th>\n",
       "      <th>insult_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57594</th>\n",
       "      <td>9a176c24d63a5c60</td>\n",
       "      <td>supertr0ll live forever don't respect supertr0...</td>\n",
       "      <td>3415</td>\n",
       "      <td>1</td>\n",
       "      <td>0.204417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140930</th>\n",
       "      <td>f22cd3ccf2ae12b1</td>\n",
       "      <td>repeat daedalus969 biznitch repeat daedalus969...</td>\n",
       "      <td>3559</td>\n",
       "      <td>1</td>\n",
       "      <td>0.048239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140590</th>\n",
       "      <td>f052b5fb53d79e12</td>\n",
       "      <td>bad admin- bad admin- bad admin- bad admin- ba...</td>\n",
       "      <td>3171</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27045</th>\n",
       "      <td>479826ff5d74ab46</td>\n",
       "      <td>hanibal911you're bastard pro assad hanibal911y...</td>\n",
       "      <td>3709</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60802</th>\n",
       "      <td>a2c45136daf70279</td>\n",
       "      <td>fuck wikipedia fuck wikipedia fuck wikipedia f...</td>\n",
       "      <td>3119</td>\n",
       "      <td>0</td>\n",
       "      <td>0.917603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79419</th>\n",
       "      <td>d485121984ec3d6d</td>\n",
       "      <td>fucking libtard coward reverts factual evidenc...</td>\n",
       "      <td>3447</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072871</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53583</th>\n",
       "      <td>8f449b8ab17e2f39</td>\n",
       "      <td>prick fire administrator prick fire administra...</td>\n",
       "      <td>3451</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96267</th>\n",
       "      <td>02dd3c9a9129c83e</td>\n",
       "      <td>bootstoots friggen gayfag lolooolbootstoots fr...</td>\n",
       "      <td>3871</td>\n",
       "      <td>1</td>\n",
       "      <td>0.079336</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "57594   9a176c24d63a5c60  supertr0ll live forever don't respect supertr0...   \n",
       "140930  f22cd3ccf2ae12b1  repeat daedalus969 biznitch repeat daedalus969...   \n",
       "140590  f052b5fb53d79e12  bad admin- bad admin- bad admin- bad admin- ba...   \n",
       "27045   479826ff5d74ab46  hanibal911you're bastard pro assad hanibal911y...   \n",
       "60802   a2c45136daf70279  fuck wikipedia fuck wikipedia fuck wikipedia f...   \n",
       "79419   d485121984ec3d6d  fucking libtard coward reverts factual evidenc...   \n",
       "53583   8f449b8ab17e2f39  prick fire administrator prick fire administra...   \n",
       "96267   02dd3c9a9129c83e  bootstoots friggen gayfag lolooolbootstoots fr...   \n",
       "\n",
       "        comment_length  insult  insult_prob  insult_pred  \n",
       "57594             3415       1     0.204417            0  \n",
       "140930            3559       1     0.048239            0  \n",
       "140590            3171       1     0.078842            0  \n",
       "27045             3709       1     0.081724            0  \n",
       "60802             3119       0     0.917603            1  \n",
       "79419             3447       1     0.072871            0  \n",
       "53583             3451       1     0.053915            0  \n",
       "96267             3871       1     0.079336            0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['comment_length'] > 3000) & (data[target] != data[target+'_pred'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[target+'_indicator'] = (data[target] != data[target+'_pred'])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226.77042143192855, 116.0, 359.83641751775787)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.mean(data['comment_length'])\n",
    "median = np.median(data['comment_length'])\n",
    "std = np.std(data['comment_length'])\n",
    "mean, median, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argsort(data['comment_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[indices[:500]][(data[target] != data[target+'_pred'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(18, 7)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[indices[-500:]][(data[target] != data['insult_pred'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23, 7)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['comment_length'] > median + 3*std) & (data[target] != data[target+'_pred'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(662, 7)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[(data['comment_length'] < median) & (data[target] != data[target+'_pred'])].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_length</th>\n",
       "      <th>insult</th>\n",
       "      <th>insult_prob</th>\n",
       "      <th>insult_pred</th>\n",
       "      <th>insult_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43797</th>\n",
       "      <td>74e4b95b9cb9834a</td>\n",
       "      <td>attack 98 .. begin not stop sock puppet proxy ...</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148898</th>\n",
       "      <td>53cb4186efea9ee2</td>\n",
       "      <td>wild goose remove phrase derive ancient irish ...</td>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022156</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89968</th>\n",
       "      <td>f0b3496b164a5c17</td>\n",
       "      <td>summary agree wikipedia article picture prefer...</td>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>0.009205</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143624</th>\n",
       "      <td>004a6e2dde1f82eb</td>\n",
       "      <td>-pron- like opportunity remind -pron- no long ...</td>\n",
       "      <td>293</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055766</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33692</th>\n",
       "      <td>59db79e849a4cfd8</td>\n",
       "      <td>hey right thing shorten european commission lo...</td>\n",
       "      <td>171</td>\n",
       "      <td>0</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                       comment_text  \\\n",
       "43797   74e4b95b9cb9834a  attack 98 .. begin not stop sock puppet proxy ...   \n",
       "148898  53cb4186efea9ee2  wild goose remove phrase derive ancient irish ...   \n",
       "89968   f0b3496b164a5c17  summary agree wikipedia article picture prefer...   \n",
       "143624  004a6e2dde1f82eb  -pron- like opportunity remind -pron- no long ...   \n",
       "33692   59db79e849a4cfd8  hey right thing shorten european commission lo...   \n",
       "\n",
       "        comment_length  insult  insult_prob  insult_pred  insult_indicator  \n",
       "43797              155       0     0.041605            0                 0  \n",
       "148898             199       0     0.022156            0                 0  \n",
       "89968              868       0     0.009205            0                 0  \n",
       "143624             293       0     0.055766            0                 0  \n",
       "33692              171       0     0.014450            0                 0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0251731fd0>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['comment_length'], data[target+'_indicator'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_indices = data[data[target+'_indicator'] == 1].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 44214, 140483, 109790, ...,  65165,  88450,   7169])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incorrect_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([554., 211.,  99.,  53.,  33.,  24.,   8.,  11.,   5.,   7.,   2.,\n",
       "          2.,   2.,   3.,   1.,   3.,   1.,   0.,   0.,   1.,   1.,   0.,\n",
       "          1.,   0.,   1.,   1.,   0.,   1.,   0.,   0.,   0.,   0.,   1.,\n",
       "          2.,   0.,   1.,   0.,   1.,   0.,   0.,   2.,   0.,   0.,   0.,\n",
       "          3.,   1.,   0.,   1.,   0.,   1.]),\n",
       " array([   4.  ,   81.34,  158.68,  236.02,  313.36,  390.7 ,  468.04,\n",
       "         545.38,  622.72,  700.06,  777.4 ,  854.74,  932.08, 1009.42,\n",
       "        1086.76, 1164.1 , 1241.44, 1318.78, 1396.12, 1473.46, 1550.8 ,\n",
       "        1628.14, 1705.48, 1782.82, 1860.16, 1937.5 , 2014.84, 2092.18,\n",
       "        2169.52, 2246.86, 2324.2 , 2401.54, 2478.88, 2556.22, 2633.56,\n",
       "        2710.9 , 2788.24, 2865.58, 2942.92, 3020.26, 3097.6 , 3174.94,\n",
       "        3252.28, 3329.62, 3406.96, 3484.3 , 3561.64, 3638.98, 3716.32,\n",
       "        3793.66, 3871.  ]),\n",
       " <a list of 50 Patch objects>)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['comment_length'][incorrect_indices], bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
